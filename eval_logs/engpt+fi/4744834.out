START 4744834: Thu 12 Oct 2023 11:16:10 AM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl'], test='../../data/qa_token_classification/annotated/test_annotated_dataset.jsonl', dev='../../data/qa_token_classification/annotated/dev_annotated_dataset.jsonl', batch=8, epochs=10, lr=1e-05, save=None, dataset=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138082
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138082
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 50
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 68
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.1429, 'learning_rate': 9.855164822432073e-06, 'epoch': 0.14}
              precision    recall  f1-score   support

       NSWER       0.00      0.00      0.00        40
     UESTION       0.00      0.00      0.00        46

   micro avg       0.00      0.00      0.00        86
   macro avg       0.00      0.00      0.00        86
weighted avg       0.00      0.00      0.00        86

{'eval_loss': 1.0362553596496582, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.43356112376613515, 'eval_runtime': 0.5581, 'eval_samples_per_second': 89.584, 'eval_steps_per_second': 7.167, 'epoch': 0.14}
{'loss': 0.0827, 'learning_rate': 9.710329644864145e-06, 'epoch': 0.29}
              precision    recall  f1-score   support

       NSWER       0.02      0.10      0.03        40
     UESTION       0.03      0.09      0.04        46

   micro avg       0.02      0.09      0.04        86
   macro avg       0.02      0.09      0.04        86
weighted avg       0.02      0.09      0.04        86

{'eval_loss': 0.8769755363464355, 'eval_precision': 0.0223463687150838, 'eval_recall': 0.09302325581395349, 'eval_f1': 0.036036036036036036, 'eval_accuracy': 0.6428752214629208, 'eval_runtime': 0.5292, 'eval_samples_per_second': 94.483, 'eval_steps_per_second': 7.559, 'epoch': 0.29}
{'loss': 0.0707, 'learning_rate': 9.565494467296217e-06, 'epoch': 0.43}
              precision    recall  f1-score   support

       NSWER       0.14      0.28      0.18        40
     UESTION       0.23      0.39      0.29        46

   micro avg       0.18      0.34      0.24        86
   macro avg       0.18      0.33      0.24        86
weighted avg       0.19      0.34      0.24        86

{'eval_loss': 0.5713686943054199, 'eval_precision': 0.18354430379746836, 'eval_recall': 0.3372093023255814, 'eval_f1': 0.23770491803278687, 'eval_accuracy': 0.7881548974943052, 'eval_runtime': 0.5895, 'eval_samples_per_second': 84.823, 'eval_steps_per_second': 6.786, 'epoch': 0.43}
{'loss': 0.0668, 'learning_rate': 9.42065928972829e-06, 'epoch': 0.58}
              precision    recall  f1-score   support

       NSWER       0.13      0.40      0.20        40
     UESTION       0.25      0.48      0.33        46

   micro avg       0.18      0.44      0.26        86
   macro avg       0.19      0.44      0.26        86
weighted avg       0.19      0.44      0.27        86

{'eval_loss': 0.5447500944137573, 'eval_precision': 0.18009478672985782, 'eval_recall': 0.4418604651162791, 'eval_f1': 0.2558922558922559, 'eval_accuracy': 0.7928372563907872, 'eval_runtime': 0.5339, 'eval_samples_per_second': 93.643, 'eval_steps_per_second': 7.491, 'epoch': 0.58}
{'loss': 0.0659, 'learning_rate': 9.275824112160362e-06, 'epoch': 0.72}
              precision    recall  f1-score   support

       NSWER       0.11      0.23      0.15        40
     UESTION       0.23      0.39      0.29        46

   micro avg       0.17      0.31      0.22        86
   macro avg       0.17      0.31      0.22        86
weighted avg       0.17      0.31      0.22        86

{'eval_loss': 0.5917980670928955, 'eval_precision': 0.16875, 'eval_recall': 0.313953488372093, 'eval_f1': 0.21951219512195122, 'eval_accuracy': 0.7679068590230321, 'eval_runtime': 0.5369, 'eval_samples_per_second': 93.122, 'eval_steps_per_second': 7.45, 'epoch': 0.72}
{'loss': 0.0573, 'learning_rate': 9.130988934592434e-06, 'epoch': 0.87}
              precision    recall  f1-score   support

       NSWER       0.20      0.47      0.28        40
     UESTION       0.25      0.48      0.33        46

   micro avg       0.23      0.48      0.31        86
   macro avg       0.23      0.48      0.31        86
weighted avg       0.23      0.48      0.31        86

{'eval_loss': 0.5528035163879395, 'eval_precision': 0.22527472527472528, 'eval_recall': 0.47674418604651164, 'eval_f1': 0.30597014925373134, 'eval_accuracy': 0.7939762085547962, 'eval_runtime': 1.5285, 'eval_samples_per_second': 32.711, 'eval_steps_per_second': 2.617, 'epoch': 0.87}
{'loss': 0.0587, 'learning_rate': 8.986153757024508e-06, 'epoch': 1.01}
              precision    recall  f1-score   support

       NSWER       0.17      0.35      0.23        40
     UESTION       0.37      0.48      0.42        46

   micro avg       0.25      0.42      0.32        86
   macro avg       0.27      0.41      0.32        86
weighted avg       0.28      0.42      0.33        86

{'eval_loss': 0.5522437691688538, 'eval_precision': 0.2535211267605634, 'eval_recall': 0.4186046511627907, 'eval_f1': 0.31578947368421056, 'eval_accuracy': 0.8085294862060238, 'eval_runtime': 0.5599, 'eval_samples_per_second': 89.301, 'eval_steps_per_second': 7.144, 'epoch': 1.01}
{'loss': 0.0436, 'learning_rate': 8.84131857945658e-06, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.20      0.42      0.27        40
     UESTION       0.29      0.50      0.37        46

   micro avg       0.24      0.47      0.32        86
   macro avg       0.24      0.46      0.32        86
weighted avg       0.25      0.47      0.32        86

{'eval_loss': 0.5583792328834534, 'eval_precision': 0.24390243902439024, 'eval_recall': 0.46511627906976744, 'eval_f1': 0.32, 'eval_accuracy': 0.7391799544419134, 'eval_runtime': 0.5362, 'eval_samples_per_second': 93.245, 'eval_steps_per_second': 7.46, 'epoch': 1.16}
{'loss': 0.047, 'learning_rate': 8.696483401888652e-06, 'epoch': 1.3}
              precision    recall  f1-score   support

       NSWER       0.16      0.38      0.23        40
     UESTION       0.26      0.57      0.35        46

   micro avg       0.21      0.48      0.29        86
   macro avg       0.21      0.47      0.29        86
weighted avg       0.21      0.48      0.30        86

{'eval_loss': 0.5962924361228943, 'eval_precision': 0.21354166666666666, 'eval_recall': 0.47674418604651164, 'eval_f1': 0.2949640287769784, 'eval_accuracy': 0.762338648443432, 'eval_runtime': 0.542, 'eval_samples_per_second': 92.247, 'eval_steps_per_second': 7.38, 'epoch': 1.3}
{'train_runtime': 3860.5186, 'train_samples_per_second': 357.677, 'train_steps_per_second': 44.712, 'train_loss': 0.0706284203423394, 'epoch': 1.3}
              precision    recall  f1-score   support

       NSWER       0.12      0.24      0.16        59
     UESTION       0.26      0.51      0.34        73

   micro avg       0.19      0.39      0.26       132
   macro avg       0.19      0.37      0.25       132
weighted avg       0.20      0.39      0.26       132

{'epoch': 1.3,
 'eval_accuracy': 0.7988121052135382,
 'eval_f1': 0.25888324873096447,
 'eval_loss': 0.4637177884578705,
 'eval_precision': 0.1946564885496183,
 'eval_recall': 0.38636363636363635,
 'eval_runtime': 0.8054,
 'eval_samples_per_second': 84.431,
 'eval_steps_per_second': 6.208}
Accuracy: 0.7988121052135382
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	1e-5	num_train_epochs	10	END 4744834: Thu 12 Oct 2023 12:25:52 PM EEST
