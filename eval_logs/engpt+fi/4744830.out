START 4744830: Thu 12 Oct 2023 11:15:58 AM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl'], test='../../data/qa_token_classification/annotated/test_annotated_dataset.jsonl', dev='../../data/qa_token_classification/annotated/dev_annotated_dataset.jsonl', batch=8, epochs=10, lr=3e-05, save=None, dataset=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138082
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138082
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 50
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 68
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.1325, 'learning_rate': 2.9565494467296216e-05, 'epoch': 0.14}
              precision    recall  f1-score   support

       NSWER       0.03      0.10      0.04        40
     UESTION       0.04      0.07      0.05        46

   micro avg       0.03      0.08      0.05        86
   macro avg       0.03      0.08      0.05        86
weighted avg       0.04      0.08      0.05        86

{'eval_loss': 0.7685872912406921, 'eval_precision': 0.0330188679245283, 'eval_recall': 0.08139534883720931, 'eval_f1': 0.04697986577181208, 'eval_accuracy': 0.6389521640091116, 'eval_runtime': 1.01, 'eval_samples_per_second': 49.503, 'eval_steps_per_second': 3.96, 'epoch': 0.14}
{'loss': 0.0888, 'learning_rate': 2.9130988934592434e-05, 'epoch': 0.29}
              precision    recall  f1-score   support

       NSWER       0.09      0.30      0.14        40
     UESTION       0.16      0.26      0.20        46

   micro avg       0.11      0.28      0.16        86
   macro avg       0.12      0.28      0.17        86
weighted avg       0.12      0.28      0.17        86

{'eval_loss': 0.7960202693939209, 'eval_precision': 0.11267605633802817, 'eval_recall': 0.27906976744186046, 'eval_f1': 0.16053511705685616, 'eval_accuracy': 0.7045051885598582, 'eval_runtime': 0.5774, 'eval_samples_per_second': 86.602, 'eval_steps_per_second': 6.928, 'epoch': 0.29}
{'loss': 0.0787, 'learning_rate': 2.8696483401888652e-05, 'epoch': 0.43}
              precision    recall  f1-score   support

       NSWER       0.13      0.23      0.17        40
     UESTION       0.16      0.15      0.16        46

   micro avg       0.14      0.19      0.16        86
   macro avg       0.15      0.19      0.16        86
weighted avg       0.15      0.19      0.16        86

{'eval_loss': 0.6106300950050354, 'eval_precision': 0.14285714285714285, 'eval_recall': 0.18604651162790697, 'eval_f1': 0.1616161616161616, 'eval_accuracy': 0.7162743609212857, 'eval_runtime': 0.5412, 'eval_samples_per_second': 92.393, 'eval_steps_per_second': 7.391, 'epoch': 0.43}
{'loss': 0.076, 'learning_rate': 2.826197786918487e-05, 'epoch': 0.58}
              precision    recall  f1-score   support

       NSWER       0.13      0.35      0.19        40
     UESTION       0.14      0.15      0.15        46

   micro avg       0.13      0.24      0.17        86
   macro avg       0.14      0.25      0.17        86
weighted avg       0.14      0.24      0.17        86

{'eval_loss': 0.6910999417304993, 'eval_precision': 0.1346153846153846, 'eval_recall': 0.2441860465116279, 'eval_f1': 0.1735537190082645, 'eval_accuracy': 0.7017210832700582, 'eval_runtime': 0.5469, 'eval_samples_per_second': 91.418, 'eval_steps_per_second': 7.313, 'epoch': 0.58}
{'loss': 0.0718, 'learning_rate': 2.7827472336481085e-05, 'epoch': 0.72}
              precision    recall  f1-score   support

       NSWER       0.04      0.10      0.06        40
     UESTION       0.21      0.28      0.24        46

   micro avg       0.11      0.20      0.14        86
   macro avg       0.13      0.19      0.15        86
weighted avg       0.13      0.20      0.16        86

{'eval_loss': 0.6232176423072815, 'eval_precision': 0.1118421052631579, 'eval_recall': 0.19767441860465115, 'eval_f1': 0.14285714285714285, 'eval_accuracy': 0.7266514806378133, 'eval_runtime': 0.5391, 'eval_samples_per_second': 92.74, 'eval_steps_per_second': 7.419, 'epoch': 0.72}
{'loss': 0.0684, 'learning_rate': 2.73929668037773e-05, 'epoch': 0.87}
              precision    recall  f1-score   support

       NSWER       0.01      0.03      0.02        40
     UESTION       0.11      0.17      0.13        46

   micro avg       0.06      0.10      0.07        86
   macro avg       0.06      0.10      0.08        86
weighted avg       0.06      0.10      0.08        86

{'eval_loss': 0.7728793621063232, 'eval_precision': 0.05732484076433121, 'eval_recall': 0.10465116279069768, 'eval_f1': 0.07407407407407407, 'eval_accuracy': 0.6675525183497849, 'eval_runtime': 0.5306, 'eval_samples_per_second': 94.231, 'eval_steps_per_second': 7.538, 'epoch': 0.87}
{'loss': 0.0673, 'learning_rate': 2.695846127107352e-05, 'epoch': 1.01}
              precision    recall  f1-score   support

       NSWER       0.09      0.25      0.14        40
     UESTION       0.15      0.15      0.15        46

   micro avg       0.11      0.20      0.14        86
   macro avg       0.12      0.20      0.14        86
weighted avg       0.12      0.20      0.14        86

{'eval_loss': 0.8652796745300293, 'eval_precision': 0.10967741935483871, 'eval_recall': 0.19767441860465115, 'eval_f1': 0.14107883817427389, 'eval_accuracy': 0.6469248291571754, 'eval_runtime': 1.5603, 'eval_samples_per_second': 32.045, 'eval_steps_per_second': 2.564, 'epoch': 1.01}
{'loss': 0.0556, 'learning_rate': 2.6523955738369736e-05, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.14      0.28      0.18        40
     UESTION       0.30      0.28      0.29        46

   micro avg       0.19      0.28      0.23        86
   macro avg       0.22      0.28      0.24        86
weighted avg       0.22      0.28      0.24        86

{'eval_loss': 0.6375373601913452, 'eval_precision': 0.1935483870967742, 'eval_recall': 0.27906976744186046, 'eval_f1': 0.22857142857142856, 'eval_accuracy': 0.7343710453049861, 'eval_runtime': 0.5377, 'eval_samples_per_second': 92.983, 'eval_steps_per_second': 7.439, 'epoch': 1.16}
{'train_runtime': 3492.4973, 'train_samples_per_second': 395.368, 'train_steps_per_second': 49.423, 'train_loss': 0.07987925567626954, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.16      0.22      0.19        59
     UESTION       0.16      0.16      0.16        73

   micro avg       0.16      0.19      0.17       132
   macro avg       0.16      0.19      0.18       132
weighted avg       0.16      0.19      0.17       132

{'epoch': 1.16,
 'eval_accuracy': 0.7779768077684548,
 'eval_f1': 0.17482517482517482,
 'eval_loss': 0.5343133211135864,
 'eval_precision': 0.16233766233766234,
 'eval_recall': 0.1893939393939394,
 'eval_runtime': 0.7897,
 'eval_samples_per_second': 86.11,
 'eval_steps_per_second': 6.332}
Accuracy: 0.7779768077684548
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	3e-5	num_train_epochs	10	END 4744830: Thu 12 Oct 2023 12:19:34 PM EEST
