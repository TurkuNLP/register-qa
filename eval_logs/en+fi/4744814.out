START 4744814: Thu 12 Oct 2023 11:14:41 AM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2'], test='../../data/qa_token_classification/annotated/test_annotated_dataset.jsonl', dev='../../data/qa_token_classification/annotated/dev_annotated_dataset.jsonl', batch=8, epochs=10, lr=5e-05, save=None, dataset=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 50
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 68
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.1382, 'learning_rate': 4.925741103784234e-05, 'epoch': 0.15}
              precision    recall  f1-score   support

       NSWER       0.06      0.10      0.08        40
     UESTION       0.03      0.04      0.04        46

   micro avg       0.05      0.07      0.06        86
   macro avg       0.05      0.07      0.06        86
weighted avg       0.04      0.07      0.05        86

{'eval_loss': 5.709930896759033, 'eval_precision': 0.045454545454545456, 'eval_recall': 0.06976744186046512, 'eval_f1': 0.055045871559633024, 'eval_accuracy': 0.45355606175651736, 'eval_runtime': 0.6262, 'eval_samples_per_second': 79.846, 'eval_steps_per_second': 6.388, 'epoch': 0.15}
{'loss': 0.0872, 'learning_rate': 4.851482207568467e-05, 'epoch': 0.3}
              precision    recall  f1-score   support

       NSWER       0.05      0.10      0.06        40
     UESTION       0.01      0.02      0.02        46

   micro avg       0.03      0.06      0.04        86
   macro avg       0.03      0.06      0.04        86
weighted avg       0.03      0.06      0.04        86

{'eval_loss': 6.199063777923584, 'eval_precision': 0.029411764705882353, 'eval_recall': 0.05813953488372093, 'eval_f1': 0.0390625, 'eval_accuracy': 0.4770944064793723, 'eval_runtime': 0.6518, 'eval_samples_per_second': 76.705, 'eval_steps_per_second': 6.136, 'epoch': 0.3}
{'loss': 0.0831, 'learning_rate': 4.7772233113527006e-05, 'epoch': 0.45}
              precision    recall  f1-score   support

       NSWER       0.10      0.15      0.12        40
     UESTION       0.00      0.00      0.00        46

   micro avg       0.05      0.07      0.06        86
   macro avg       0.05      0.07      0.06        86
weighted avg       0.05      0.07      0.06        86

{'eval_loss': 6.947264194488525, 'eval_precision': 0.05042016806722689, 'eval_recall': 0.06976744186046512, 'eval_f1': 0.058536585365853655, 'eval_accuracy': 0.4759554543153632, 'eval_runtime': 1.6336, 'eval_samples_per_second': 30.607, 'eval_steps_per_second': 2.449, 'epoch': 0.45}
{'loss': 0.0745, 'learning_rate': 4.7029644151369336e-05, 'epoch': 0.59}
              precision    recall  f1-score   support

       NSWER       0.07      0.12      0.09        40
     UESTION       0.01      0.02      0.02        46

   micro avg       0.04      0.07      0.05        86
   macro avg       0.04      0.07      0.06        86
weighted avg       0.04      0.07      0.05        86

{'eval_loss': 6.998560905456543, 'eval_precision': 0.044444444444444446, 'eval_recall': 0.06976744186046512, 'eval_f1': 0.05429864253393665, 'eval_accuracy': 0.48544672234877245, 'eval_runtime': 0.6014, 'eval_samples_per_second': 83.141, 'eval_steps_per_second': 6.651, 'epoch': 0.59}
{'loss': 0.0693, 'learning_rate': 4.628705518921167e-05, 'epoch': 0.74}
              precision    recall  f1-score   support

       NSWER       0.11      0.17      0.13        40
     UESTION       0.00      0.00      0.00        46

   micro avg       0.05      0.08      0.07        86
   macro avg       0.05      0.09      0.07        86
weighted avg       0.05      0.08      0.06        86

{'eval_loss': 8.484405517578125, 'eval_precision': 0.05426356589147287, 'eval_recall': 0.08139534883720931, 'eval_f1': 0.06511627906976743, 'eval_accuracy': 0.4698810427739813, 'eval_runtime': 0.5991, 'eval_samples_per_second': 83.452, 'eval_steps_per_second': 6.676, 'epoch': 0.74}
{'loss': 0.0675, 'learning_rate': 4.5544466227054e-05, 'epoch': 0.89}
              precision    recall  f1-score   support

       NSWER       0.11      0.12      0.12        40
     UESTION       0.00      0.00      0.00        46

   micro avg       0.05      0.06      0.05        86
   macro avg       0.06      0.06      0.06        86
weighted avg       0.05      0.06      0.05        86

{'eval_loss': 9.554720878601074, 'eval_precision': 0.05154639175257732, 'eval_recall': 0.05813953488372093, 'eval_f1': 0.0546448087431694, 'eval_accuracy': 0.43976208554796253, 'eval_runtime': 0.6, 'eval_samples_per_second': 83.337, 'eval_steps_per_second': 6.667, 'epoch': 0.89}
{'train_runtime': 2603.478, 'train_samples_per_second': 517.224, 'train_steps_per_second': 64.656, 'train_loss': 0.08664112955729167, 'epoch': 0.89}
              precision    recall  f1-score   support

       NSWER       0.08      0.14      0.10        59
     UESTION       0.04      0.07      0.05        73

   micro avg       0.06      0.10      0.07       132
   macro avg       0.06      0.10      0.08       132
weighted avg       0.06      0.10      0.07       132

{'epoch': 0.89,
 'eval_accuracy': 0.4747808051286886,
 'eval_f1': 0.07428571428571429,
 'eval_loss': 5.758930206298828,
 'eval_precision': 0.05963302752293578,
 'eval_recall': 0.09848484848484848,
 'eval_runtime': 1.0416,
 'eval_samples_per_second': 65.286,
 'eval_steps_per_second': 4.8}
Accuracy: 0.4747808051286886
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	5e-5	num_train_epochs	10	END 4744814: Thu 12 Oct 2023 12:02:15 PM EEST
