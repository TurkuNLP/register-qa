START 4753290: Fri 13 Oct 2023 12:31:54 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/cleaned2_train_annotated_dataset.jsonl', '../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl'], test='../../data/qa_token_classification/annotated/en_test_dataset.jsonl', dev='../../data/qa_token_classification/annotated/en_dev_dataset.jsonl', batch=8, epochs=10, lr=5e-05, save=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
in dictionary: 2
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138182
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138182
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 40
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 60
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.1685, 'learning_rate': 4.927632721588607e-05, 'epoch': 0.14}
              precision    recall  f1-score   support

       NSWER       0.05      0.07      0.06        40
     UESTION       0.05      0.04      0.05        92

   micro avg       0.05      0.05      0.05       132
   macro avg       0.05      0.06      0.05       132
weighted avg       0.05      0.05      0.05       132

{'eval_loss': 5.6021342277526855, 'eval_precision': 0.050724637681159424, 'eval_recall': 0.05303030303030303, 'eval_f1': 0.05185185185185185, 'eval_accuracy': 0.3391260162601626, 'eval_runtime': 0.5888, 'eval_samples_per_second': 67.933, 'eval_steps_per_second': 5.095, 'epoch': 0.14}
{'loss': 0.1166, 'learning_rate': 4.855265443177213e-05, 'epoch': 0.29}
              precision    recall  f1-score   support

       NSWER       0.07      0.12      0.09        40
     UESTION       0.04      0.03      0.04        92

   micro avg       0.06      0.06      0.06       132
   macro avg       0.06      0.08      0.06       132
weighted avg       0.05      0.06      0.05       132

{'eval_loss': 5.608819007873535, 'eval_precision': 0.055944055944055944, 'eval_recall': 0.06060606060606061, 'eval_f1': 0.05818181818181819, 'eval_accuracy': 0.3283536585365854, 'eval_runtime': 0.5738, 'eval_samples_per_second': 69.706, 'eval_steps_per_second': 5.228, 'epoch': 0.29}
{'loss': 0.1045, 'learning_rate': 4.78289816476582e-05, 'epoch': 0.43}
              precision    recall  f1-score   support

       NSWER       0.04      0.07      0.05        40
     UESTION       0.02      0.02      0.02        92

   micro avg       0.03      0.04      0.03       132
   macro avg       0.03      0.05      0.04       132
weighted avg       0.03      0.04      0.03       132

{'eval_loss': 3.794802188873291, 'eval_precision': 0.03225806451612903, 'eval_recall': 0.03787878787878788, 'eval_f1': 0.0348432055749129, 'eval_accuracy': 0.38983739837398373, 'eval_runtime': 0.5693, 'eval_samples_per_second': 70.266, 'eval_steps_per_second': 5.27, 'epoch': 0.43}
{'loss': 0.1026, 'learning_rate': 4.710530886354426e-05, 'epoch': 0.58}
              precision    recall  f1-score   support

       NSWER       0.03      0.05      0.04        40
     UESTION       0.04      0.03      0.04        92

   micro avg       0.04      0.04      0.04       132
   macro avg       0.04      0.04      0.04       132
weighted avg       0.04      0.04      0.04       132

{'eval_loss': 6.150135517120361, 'eval_precision': 0.036231884057971016, 'eval_recall': 0.03787878787878788, 'eval_f1': 0.037037037037037035, 'eval_accuracy': 0.3301829268292683, 'eval_runtime': 0.6026, 'eval_samples_per_second': 66.382, 'eval_steps_per_second': 4.979, 'epoch': 0.58}
{'loss': 0.0919, 'learning_rate': 4.638163607943033e-05, 'epoch': 0.72}
              precision    recall  f1-score   support

       NSWER       0.05      0.10      0.06        40
     UESTION       0.04      0.04      0.04        92

   micro avg       0.04      0.06      0.05       132
   macro avg       0.04      0.07      0.05       132
weighted avg       0.04      0.06      0.05       132

{'eval_loss': 5.50460147857666, 'eval_precision': 0.044444444444444446, 'eval_recall': 0.06060606060606061, 'eval_f1': 0.05128205128205128, 'eval_accuracy': 0.35884146341463413, 'eval_runtime': 0.58, 'eval_samples_per_second': 68.967, 'eval_steps_per_second': 5.173, 'epoch': 0.72}
{'loss': 0.0911, 'learning_rate': 4.565796329531639e-05, 'epoch': 0.87}
              precision    recall  f1-score   support

       NSWER       0.03      0.07      0.04        40
     UESTION       0.03      0.04      0.04        92

   micro avg       0.03      0.05      0.04       132
   macro avg       0.03      0.06      0.04       132
weighted avg       0.03      0.05      0.04       132

{'eval_loss': 5.641446113586426, 'eval_precision': 0.029661016949152543, 'eval_recall': 0.05303030303030303, 'eval_f1': 0.03804347826086957, 'eval_accuracy': 0.3433943089430894, 'eval_runtime': 0.6746, 'eval_samples_per_second': 59.294, 'eval_steps_per_second': 4.447, 'epoch': 0.87}
{'loss': 0.0896, 'learning_rate': 4.4934290511202456e-05, 'epoch': 1.01}
              precision    recall  f1-score   support

       NSWER       0.07      0.10      0.08        40
     UESTION       0.05      0.03      0.04        92

   micro avg       0.06      0.05      0.05       132
   macro avg       0.06      0.07      0.06       132
weighted avg       0.05      0.05      0.05       132

{'eval_loss': 6.188662052154541, 'eval_precision': 0.05511811023622047, 'eval_recall': 0.05303030303030303, 'eval_f1': 0.05405405405405406, 'eval_accuracy': 0.30416666666666664, 'eval_runtime': 0.576, 'eval_samples_per_second': 69.445, 'eval_steps_per_second': 5.208, 'epoch': 1.01}
{'loss': 0.0767, 'learning_rate': 4.421061772708852e-05, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.03      0.05      0.04        40
     UESTION       0.04      0.03      0.04        92

   micro avg       0.04      0.04      0.04       132
   macro avg       0.04      0.04      0.04       132
weighted avg       0.04      0.04      0.04       132

{'eval_loss': 5.380767345428467, 'eval_precision': 0.03731343283582089, 'eval_recall': 0.03787878787878788, 'eval_f1': 0.03759398496240601, 'eval_accuracy': 0.3696138211382114, 'eval_runtime': 0.5849, 'eval_samples_per_second': 68.384, 'eval_steps_per_second': 5.129, 'epoch': 1.16}
{'train_runtime': 3448.7428, 'train_samples_per_second': 400.674, 'train_steps_per_second': 50.085, 'train_loss': 0.10518918228149414, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.04      0.03      0.03        79
     UESTION       0.04      0.04      0.04       109

   micro avg       0.04      0.03      0.04       188
   macro avg       0.04      0.03      0.04       188
weighted avg       0.04      0.03      0.04       188

{'epoch': 1.16,
 'eval_accuracy': 0.3361711109547597,
 'eval_f1': 0.03614457831325301,
 'eval_loss': 3.9542007446289062,
 'eval_precision': 0.041666666666666664,
 'eval_recall': 0.031914893617021274,
 'eval_runtime': 0.9314,
 'eval_samples_per_second': 64.421,
 'eval_steps_per_second': 4.295}
Accuracy: 0.3361711109547597
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	5e-5	num_train_epochs	10	END 4753290: Fri 13 Oct 2023 01:34:22 PM EEST
