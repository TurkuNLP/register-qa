START 4753302: Fri 13 Oct 2023 12:38:35 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/cleaned2_train_annotated_dataset.jsonl'], test='../../data/qa_token_classification/annotated/en_test_dataset.jsonl', dev='../../data/qa_token_classification/annotated/en_dev_dataset.jsonl', batch=8, epochs=10, lr=2e-05, save=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 134758
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 134758
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 40
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 60
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.2866, 'learning_rate': 1.9970317601662218e-05, 'epoch': 0.01}
              precision    recall  f1-score   support

       NSWER       0.02      0.07      0.03        40
     UESTION       0.01      0.01      0.01        92

   micro avg       0.01      0.03      0.02       132
   macro avg       0.01      0.04      0.02       132
weighted avg       0.01      0.03      0.01       132

{'eval_loss': 4.644125461578369, 'eval_precision': 0.0103359173126615, 'eval_recall': 0.030303030303030304, 'eval_f1': 0.015414258188824661, 'eval_accuracy': 0.26951219512195124, 'eval_runtime': 0.5298, 'eval_samples_per_second': 75.494, 'eval_steps_per_second': 5.662, 'epoch': 0.01}
{'loss': 0.1734, 'learning_rate': 1.994063520332443e-05, 'epoch': 0.03}
              precision    recall  f1-score   support

       NSWER       0.01      0.05      0.02        40
     UESTION       0.01      0.02      0.01        92

   micro avg       0.01      0.03      0.02       132
   macro avg       0.01      0.04      0.02       132
weighted avg       0.01      0.03      0.02       132

{'eval_loss': 4.7553181648254395, 'eval_precision': 0.011111111111111112, 'eval_recall': 0.030303030303030304, 'eval_f1': 0.016260162601626015, 'eval_accuracy': 0.3153455284552846, 'eval_runtime': 0.5286, 'eval_samples_per_second': 75.678, 'eval_steps_per_second': 5.676, 'epoch': 0.03}
{'loss': 0.1378, 'learning_rate': 1.9910952804986647e-05, 'epoch': 0.04}
              precision    recall  f1-score   support

       NSWER       0.02      0.05      0.03        40
     UESTION       0.02      0.03      0.03        92

   micro avg       0.02      0.04      0.03       132
   macro avg       0.02      0.04      0.03       132
weighted avg       0.02      0.04      0.03       132

{'eval_loss': 5.137739658355713, 'eval_precision': 0.02100840336134454, 'eval_recall': 0.03787878787878788, 'eval_f1': 0.027027027027027032, 'eval_accuracy': 0.32439024390243903, 'eval_runtime': 0.5305, 'eval_samples_per_second': 75.403, 'eval_steps_per_second': 5.655, 'epoch': 0.04}
{'loss': 0.1245, 'learning_rate': 1.988127040664886e-05, 'epoch': 0.06}
              precision    recall  f1-score   support

       NSWER       0.01      0.05      0.02        40
     UESTION       0.03      0.04      0.03        92

   micro avg       0.02      0.05      0.03       132
   macro avg       0.02      0.05      0.03       132
weighted avg       0.02      0.05      0.03       132

{'eval_loss': 4.787911415100098, 'eval_precision': 0.019867549668874173, 'eval_recall': 0.045454545454545456, 'eval_f1': 0.027649769585253458, 'eval_accuracy': 0.3201219512195122, 'eval_runtime': 0.5243, 'eval_samples_per_second': 76.294, 'eval_steps_per_second': 5.722, 'epoch': 0.06}
{'loss': 0.1038, 'learning_rate': 1.9851588008311072e-05, 'epoch': 0.07}
              precision    recall  f1-score   support

       NSWER       0.03      0.10      0.04        40
     UESTION       0.03      0.04      0.03        92

   micro avg       0.03      0.06      0.04       132
   macro avg       0.03      0.07      0.04       132
weighted avg       0.03      0.06      0.04       132

{'eval_loss': 5.279183864593506, 'eval_precision': 0.028070175438596492, 'eval_recall': 0.06060606060606061, 'eval_f1': 0.03836930455635492, 'eval_accuracy': 0.32164634146341464, 'eval_runtime': 0.5269, 'eval_samples_per_second': 75.909, 'eval_steps_per_second': 5.693, 'epoch': 0.07}
{'loss': 0.095, 'learning_rate': 1.9821905609973285e-05, 'epoch': 0.09}
              precision    recall  f1-score   support

       NSWER       0.02      0.07      0.04        40
     UESTION       0.02      0.03      0.03        92

   micro avg       0.02      0.05      0.03       132
   macro avg       0.02      0.05      0.03       132
weighted avg       0.02      0.05      0.03       132

{'eval_loss': 4.849386692047119, 'eval_precision': 0.023809523809523808, 'eval_recall': 0.045454545454545456, 'eval_f1': 0.03125, 'eval_accuracy': 0.3433943089430894, 'eval_runtime': 0.526, 'eval_samples_per_second': 76.053, 'eval_steps_per_second': 5.704, 'epoch': 0.09}
{'train_runtime': 280.3423, 'train_samples_per_second': 4806.91, 'train_steps_per_second': 600.873, 'train_loss': 0.1535410614013672, 'epoch': 0.09}
              precision    recall  f1-score   support

       NSWER       0.01      0.04      0.02        79
     UESTION       0.01      0.04      0.02       109

   micro avg       0.01      0.04      0.02       188
   macro avg       0.01      0.04      0.02       188
weighted avg       0.01      0.04      0.02       188

{'epoch': 0.09,
 'eval_accuracy': 0.26299866319566595,
 'eval_f1': 0.01891891891891892,
 'eval_loss': 4.7476043701171875,
 'eval_precision': 0.012681159420289856,
 'eval_recall': 0.03723404255319149,
 'eval_runtime': 0.8002,
 'eval_samples_per_second': 74.985,
 'eval_steps_per_second': 4.999}
Accuracy: 0.26299866319566595
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	2e-5	num_train_epochs	10	END 4753302: Fri 13 Oct 2023 12:48:03 PM EEST
