START 4753169: Fri 13 Oct 2023 12:18:34 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl'], test='../../data/qa_token_classification/annotated/en_test_dataset.jsonl', dev='../../data/qa_token_classification/annotated/en_dev_dataset.jsonl', batch=8, epochs=10, lr=1e-05, save=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138082
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138082
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 40
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 60
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.1296, 'learning_rate': 9.855164822432073e-06, 'epoch': 0.14}
              precision    recall  f1-score   support

       NSWER       0.05      0.15      0.08        40
     UESTION       0.04      0.05      0.05        92

   micro avg       0.05      0.08      0.06       132
   macro avg       0.05      0.10      0.06       132
weighted avg       0.04      0.08      0.06       132

{'eval_loss': 4.029642105102539, 'eval_precision': 0.04602510460251046, 'eval_recall': 0.08333333333333333, 'eval_f1': 0.05929919137466308, 'eval_accuracy': 0.358739837398374, 'eval_runtime': 0.5938, 'eval_samples_per_second': 67.367, 'eval_steps_per_second': 5.053, 'epoch': 0.14}
{'loss': 0.0871, 'learning_rate': 9.710329644864145e-06, 'epoch': 0.29}
              precision    recall  f1-score   support

       NSWER       0.05      0.15      0.08        40
     UESTION       0.04      0.05      0.05        92

   micro avg       0.05      0.08      0.06       132
   macro avg       0.05      0.10      0.06       132
weighted avg       0.05      0.08      0.06       132

{'eval_loss': 4.38096809387207, 'eval_precision': 0.047619047619047616, 'eval_recall': 0.08333333333333333, 'eval_f1': 0.060606060606060615, 'eval_accuracy': 0.34827235772357723, 'eval_runtime': 0.5708, 'eval_samples_per_second': 70.076, 'eval_steps_per_second': 5.256, 'epoch': 0.29}
{'loss': 0.0706, 'learning_rate': 9.565494467296217e-06, 'epoch': 0.43}
              precision    recall  f1-score   support

       NSWER       0.03      0.07      0.04        40
     UESTION       0.04      0.04      0.04        92

   micro avg       0.03      0.05      0.04       132
   macro avg       0.03      0.06      0.04       132
weighted avg       0.04      0.05      0.04       132

{'eval_loss': 4.512351989746094, 'eval_precision': 0.034653465346534656, 'eval_recall': 0.05303030303030303, 'eval_f1': 0.04191616766467066, 'eval_accuracy': 0.34176829268292686, 'eval_runtime': 0.5726, 'eval_samples_per_second': 69.859, 'eval_steps_per_second': 5.239, 'epoch': 0.43}
{'loss': 0.0691, 'learning_rate': 9.42065928972829e-06, 'epoch': 0.58}
              precision    recall  f1-score   support

       NSWER       0.04      0.12      0.06        40
     UESTION       0.02      0.03      0.02        92

   micro avg       0.03      0.06      0.04       132
   macro avg       0.03      0.08      0.04       132
weighted avg       0.03      0.06      0.04       132

{'eval_loss': 2.893173933029175, 'eval_precision': 0.02857142857142857, 'eval_recall': 0.06060606060606061, 'eval_f1': 0.03883495145631068, 'eval_accuracy': 0.375609756097561, 'eval_runtime': 0.5723, 'eval_samples_per_second': 69.89, 'eval_steps_per_second': 5.242, 'epoch': 0.58}
{'loss': 0.0638, 'learning_rate': 9.275824112160362e-06, 'epoch': 0.72}
              precision    recall  f1-score   support

       NSWER       0.04      0.07      0.05        40
     UESTION       0.04      0.05      0.05        92

   micro avg       0.04      0.06      0.05       132
   macro avg       0.04      0.06      0.05       132
weighted avg       0.04      0.06      0.05       132

{'eval_loss': 3.8576197624206543, 'eval_precision': 0.04060913705583756, 'eval_recall': 0.06060606060606061, 'eval_f1': 0.048632218844984795, 'eval_accuracy': 0.3615853658536585, 'eval_runtime': 0.5727, 'eval_samples_per_second': 69.84, 'eval_steps_per_second': 5.238, 'epoch': 0.72}
{'loss': 0.0651, 'learning_rate': 9.130988934592434e-06, 'epoch': 0.87}
              precision    recall  f1-score   support

       NSWER       0.05      0.12      0.07        40
     UESTION       0.06      0.08      0.07        92

   micro avg       0.06      0.09      0.07       132
   macro avg       0.05      0.10      0.07       132
weighted avg       0.06      0.09      0.07       132

{'eval_loss': 3.5880229473114014, 'eval_precision': 0.05504587155963303, 'eval_recall': 0.09090909090909091, 'eval_f1': 0.06857142857142857, 'eval_accuracy': 0.40233739837398375, 'eval_runtime': 0.5603, 'eval_samples_per_second': 71.389, 'eval_steps_per_second': 5.354, 'epoch': 0.87}
{'loss': 0.0538, 'learning_rate': 8.986153757024508e-06, 'epoch': 1.01}
              precision    recall  f1-score   support

       NSWER       0.09      0.28      0.14        40
     UESTION       0.06      0.08      0.07        92

   micro avg       0.08      0.14      0.10       132
   macro avg       0.08      0.18      0.10       132
weighted avg       0.07      0.14      0.09       132

{'eval_loss': 5.487409591674805, 'eval_precision': 0.07659574468085106, 'eval_recall': 0.13636363636363635, 'eval_f1': 0.09809264305177112, 'eval_accuracy': 0.3648373983739837, 'eval_runtime': 0.5775, 'eval_samples_per_second': 69.268, 'eval_steps_per_second': 5.195, 'epoch': 1.01}
{'loss': 0.0466, 'learning_rate': 8.84131857945658e-06, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.12      0.25      0.16        40
     UESTION       0.07      0.07      0.07        92

   micro avg       0.09      0.12      0.10       132
   macro avg       0.09      0.16      0.11       132
weighted avg       0.08      0.12      0.09       132

{'eval_loss': 5.488423824310303, 'eval_precision': 0.09142857142857143, 'eval_recall': 0.12121212121212122, 'eval_f1': 0.10423452768729642, 'eval_accuracy': 0.3673780487804878, 'eval_runtime': 0.5764, 'eval_samples_per_second': 69.39, 'eval_steps_per_second': 5.204, 'epoch': 1.16}
{'loss': 0.0439, 'learning_rate': 8.696483401888652e-06, 'epoch': 1.3}
              precision    recall  f1-score   support

       NSWER       0.05      0.15      0.07        40
     UESTION       0.03      0.04      0.04        92

   micro avg       0.04      0.08      0.05       132
   macro avg       0.04      0.10      0.05       132
weighted avg       0.04      0.08      0.05       132

{'eval_loss': 4.492898464202881, 'eval_precision': 0.038910505836575876, 'eval_recall': 0.07575757575757576, 'eval_f1': 0.05141388174807198, 'eval_accuracy': 0.3915650406504065, 'eval_runtime': 0.618, 'eval_samples_per_second': 64.724, 'eval_steps_per_second': 4.854, 'epoch': 1.3}
{'train_runtime': 4060.5553, 'train_samples_per_second': 340.057, 'train_steps_per_second': 42.509, 'train_loss': 0.06995503980848525, 'epoch': 1.3}
              precision    recall  f1-score   support

       NSWER       0.10      0.18      0.13        79
     UESTION       0.04      0.06      0.04       109

   micro avg       0.07      0.11      0.08       188
   macro avg       0.07      0.12      0.09       188
weighted avg       0.06      0.11      0.08       188

{'epoch': 1.3,
 'eval_accuracy': 0.35136846548934075,
 'eval_f1': 0.081799591002045,
 'eval_loss': 3.590420961380005,
 'eval_precision': 0.0664451827242525,
 'eval_recall': 0.10638297872340426,
 'eval_runtime': 0.8766,
 'eval_samples_per_second': 68.449,
 'eval_steps_per_second': 4.563}
Accuracy: 0.35136846548934075
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	1e-5	num_train_epochs	10	END 4753169: Fri 13 Oct 2023 01:31:39 PM EEST
