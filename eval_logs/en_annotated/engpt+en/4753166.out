START 4753166: Fri 13 Oct 2023 12:18:34 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl'], test='../../data/qa_token_classification/annotated/en_test_dataset.jsonl', dev='../../data/qa_token_classification/annotated/en_dev_dataset.jsonl', batch=8, epochs=10, lr=5e-05, save=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138082
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138082
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 40
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 60
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.1457, 'learning_rate': 4.927582411216036e-05, 'epoch': 0.14}
              precision    recall  f1-score   support

       NSWER       0.02      0.05      0.03        40
     UESTION       0.05      0.04      0.05        92

   micro avg       0.03      0.05      0.04       132
   macro avg       0.04      0.05      0.04       132
weighted avg       0.04      0.05      0.04       132

{'eval_loss': 5.573047637939453, 'eval_precision': 0.03468208092485549, 'eval_recall': 0.045454545454545456, 'eval_f1': 0.039344262295081964, 'eval_accuracy': 0.31595528455284555, 'eval_runtime': 0.6151, 'eval_samples_per_second': 65.03, 'eval_steps_per_second': 4.877, 'epoch': 0.14}
{'loss': 0.1016, 'learning_rate': 4.855164822432072e-05, 'epoch': 0.29}
              precision    recall  f1-score   support

       NSWER       0.01      0.03      0.02        40
     UESTION       0.04      0.03      0.04        92

   micro avg       0.03      0.03      0.03       132
   macro avg       0.03      0.03      0.03       132
weighted avg       0.03      0.03      0.03       132

{'eval_loss': 6.421370506286621, 'eval_precision': 0.02666666666666667, 'eval_recall': 0.030303030303030304, 'eval_f1': 0.028368794326241134, 'eval_accuracy': 0.3590447154471545, 'eval_runtime': 0.5752, 'eval_samples_per_second': 69.543, 'eval_steps_per_second': 5.216, 'epoch': 0.29}
{'loss': 0.0964, 'learning_rate': 4.7827472336481086e-05, 'epoch': 0.43}
              precision    recall  f1-score   support

       NSWER       0.06      0.10      0.07        40
     UESTION       0.01      0.01      0.01        92

   micro avg       0.03      0.04      0.03       132
   macro avg       0.03      0.06      0.04       132
weighted avg       0.03      0.04      0.03       132

{'eval_loss': 5.30778169631958, 'eval_precision': 0.03205128205128205, 'eval_recall': 0.03787878787878788, 'eval_f1': 0.034722222222222224, 'eval_accuracy': 0.325609756097561, 'eval_runtime': 0.5758, 'eval_samples_per_second': 69.467, 'eval_steps_per_second': 5.21, 'epoch': 0.43}
{'loss': 0.0921, 'learning_rate': 4.7103296448641445e-05, 'epoch': 0.58}
              precision    recall  f1-score   support

       NSWER       0.04      0.05      0.04        40
     UESTION       0.03      0.02      0.03        92

   micro avg       0.03      0.03      0.03       132
   macro avg       0.03      0.04      0.03       132
weighted avg       0.03      0.03      0.03       132

{'eval_loss': 6.029511451721191, 'eval_precision': 0.034782608695652174, 'eval_recall': 0.030303030303030304, 'eval_f1': 0.03238866396761134, 'eval_accuracy': 0.33140243902439026, 'eval_runtime': 0.5752, 'eval_samples_per_second': 69.543, 'eval_steps_per_second': 5.216, 'epoch': 0.58}
{'loss': 0.0893, 'learning_rate': 4.637912056080181e-05, 'epoch': 0.72}
              precision    recall  f1-score   support

       NSWER       0.03      0.07      0.04        40
     UESTION       0.04      0.05      0.05        92

   micro avg       0.03      0.06      0.04       132
   macro avg       0.03      0.06      0.04       132
weighted avg       0.04      0.06      0.04       132

{'eval_loss': 6.038179397583008, 'eval_precision': 0.034482758620689655, 'eval_recall': 0.06060606060606061, 'eval_f1': 0.04395604395604396, 'eval_accuracy': 0.3458333333333333, 'eval_runtime': 0.576, 'eval_samples_per_second': 69.444, 'eval_steps_per_second': 5.208, 'epoch': 0.72}
{'loss': 0.0904, 'learning_rate': 4.565494467296217e-05, 'epoch': 0.87}
              precision    recall  f1-score   support

       NSWER       0.03      0.07      0.04        40
     UESTION       0.02      0.02      0.02        92

   micro avg       0.03      0.04      0.03       132
   macro avg       0.03      0.05      0.03       132
weighted avg       0.02      0.04      0.03       132

{'eval_loss': 6.2109055519104, 'eval_precision': 0.02564102564102564, 'eval_recall': 0.03787878787878788, 'eval_f1': 0.03058103975535168, 'eval_accuracy': 0.3413617886178862, 'eval_runtime': 0.5742, 'eval_samples_per_second': 69.662, 'eval_steps_per_second': 5.225, 'epoch': 0.87}
{'loss': 0.0814, 'learning_rate': 4.4930768785122536e-05, 'epoch': 1.01}
              precision    recall  f1-score   support

       NSWER       0.05      0.07      0.06        40
     UESTION       0.06      0.04      0.05        92

   micro avg       0.05      0.05      0.05       132
   macro avg       0.05      0.06      0.05       132
weighted avg       0.06      0.05      0.05       132

{'eval_loss': 5.634079933166504, 'eval_precision': 0.05343511450381679, 'eval_recall': 0.05303030303030303, 'eval_f1': 0.053231939163498096, 'eval_accuracy': 0.3611788617886179, 'eval_runtime': 0.576, 'eval_samples_per_second': 69.439, 'eval_steps_per_second': 5.208, 'epoch': 1.01}
{'loss': 0.0724, 'learning_rate': 4.4206592897282895e-05, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.04      0.07      0.05        40
     UESTION       0.05      0.04      0.05        92

   micro avg       0.04      0.05      0.05       132
   macro avg       0.04      0.06      0.05       132
weighted avg       0.04      0.05      0.05       132

{'eval_loss': 6.021279811859131, 'eval_precision': 0.041666666666666664, 'eval_recall': 0.05303030303030303, 'eval_f1': 0.04666666666666666, 'eval_accuracy': 0.35528455284552846, 'eval_runtime': 0.5785, 'eval_samples_per_second': 69.147, 'eval_steps_per_second': 5.186, 'epoch': 1.16}
{'train_runtime': 3508.6063, 'train_samples_per_second': 393.552, 'train_steps_per_second': 49.196, 'train_loss': 0.09615622253417969, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.06      0.10      0.08        79
     UESTION       0.03      0.04      0.03       109

   micro avg       0.05      0.06      0.05       188
   macro avg       0.05      0.07      0.06       188
weighted avg       0.04      0.06      0.05       188

{'epoch': 1.16,
 'eval_accuracy': 0.27376345599099416,
 'eval_f1': 0.05393258426966292,
 'eval_loss': 5.618110656738281,
 'eval_precision': 0.04669260700389105,
 'eval_recall': 0.06382978723404255,
 'eval_runtime': 0.9062,
 'eval_samples_per_second': 66.213,
 'eval_steps_per_second': 4.414}
Accuracy: 0.27376345599099416
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	5e-5	num_train_epochs	10	END 4753166: Fri 13 Oct 2023 01:22:29 PM EEST
