START 4753310: Fri 13 Oct 2023 12:38:35 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/annotated/cleaned2_train_annotated_dataset.jsonl', '../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl'], test='../../data/qa_token_classification/annotated/en_test_dataset.jsonl', dev='../../data/qa_token_classification/annotated/en_dev_dataset.jsonl', batch=8, epochs=10, lr=5e-05, save=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3524
    })
})
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3524
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 40
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 60
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.8683, 'learning_rate': 4.71655328798186e-05, 'epoch': 0.57}
              precision    recall  f1-score   support

       NSWER       0.03      0.10      0.04        40
     UESTION       0.27      0.33      0.30        92

   micro avg       0.13      0.26      0.17       132
   macro avg       0.15      0.21      0.17       132
weighted avg       0.20      0.26      0.22       132

{'eval_loss': 0.6620158553123474, 'eval_precision': 0.13229571984435798, 'eval_recall': 0.25757575757575757, 'eval_f1': 0.17480719794344476, 'eval_accuracy': 0.7066056910569106, 'eval_runtime': 0.5144, 'eval_samples_per_second': 77.757, 'eval_steps_per_second': 5.832, 'epoch': 0.57}
{'loss': 0.7153, 'learning_rate': 4.433106575963719e-05, 'epoch': 1.13}
              precision    recall  f1-score   support

       NSWER       0.07      0.28      0.12        40
     UESTION       0.30      0.33      0.31        92

   micro avg       0.16      0.31      0.22       132
   macro avg       0.19      0.30      0.21       132
weighted avg       0.23      0.31      0.25       132

{'eval_loss': 0.5293188095092773, 'eval_precision': 0.1646586345381526, 'eval_recall': 0.3106060606060606, 'eval_f1': 0.2152230971128609, 'eval_accuracy': 0.7790650406504065, 'eval_runtime': 0.4958, 'eval_samples_per_second': 80.685, 'eval_steps_per_second': 6.051, 'epoch': 1.13}
{'loss': 0.6496, 'learning_rate': 4.149659863945579e-05, 'epoch': 1.7}
              precision    recall  f1-score   support

       NSWER       0.08      0.33      0.13        40
     UESTION       0.23      0.26      0.24        92

   micro avg       0.14      0.28      0.19       132
   macro avg       0.16      0.29      0.19       132
weighted avg       0.19      0.28      0.21       132

{'eval_loss': 0.6039506196975708, 'eval_precision': 0.14285714285714285, 'eval_recall': 0.2803030303030303, 'eval_f1': 0.18925831202046037, 'eval_accuracy': 0.749390243902439, 'eval_runtime': 0.506, 'eval_samples_per_second': 79.058, 'eval_steps_per_second': 5.929, 'epoch': 1.7}
{'loss': 0.597, 'learning_rate': 3.8662131519274384e-05, 'epoch': 2.27}
              precision    recall  f1-score   support

       NSWER       0.13      0.38      0.19        40
     UESTION       0.28      0.34      0.31        92

   micro avg       0.20      0.35      0.25       132
   macro avg       0.20      0.36      0.25       132
weighted avg       0.23      0.35      0.27       132

{'eval_loss': 0.5634692311286926, 'eval_precision': 0.20087336244541484, 'eval_recall': 0.3484848484848485, 'eval_f1': 0.2548476454293629, 'eval_accuracy': 0.7728658536585366, 'eval_runtime': 0.5086, 'eval_samples_per_second': 78.647, 'eval_steps_per_second': 5.899, 'epoch': 2.27}
{'loss': 0.536, 'learning_rate': 3.5827664399092974e-05, 'epoch': 2.83}
              precision    recall  f1-score   support

       NSWER       0.10      0.28      0.15        40
     UESTION       0.27      0.26      0.27        92

   micro avg       0.18      0.27      0.22       132
   macro avg       0.19      0.27      0.21       132
weighted avg       0.22      0.27      0.23       132

{'eval_loss': 0.66211998462677, 'eval_precision': 0.18134715025906736, 'eval_recall': 0.26515151515151514, 'eval_f1': 0.2153846153846154, 'eval_accuracy': 0.7638211382113821, 'eval_runtime': 0.4878, 'eval_samples_per_second': 82.002, 'eval_steps_per_second': 6.15, 'epoch': 2.83}
{'loss': 0.4739, 'learning_rate': 3.2993197278911564e-05, 'epoch': 3.4}
              precision    recall  f1-score   support

       NSWER       0.12      0.35      0.18        40
     UESTION       0.32      0.29      0.31        92

   micro avg       0.20      0.31      0.25       132
   macro avg       0.22      0.32      0.24       132
weighted avg       0.26      0.31      0.27       132

{'eval_loss': 0.5975290536880493, 'eval_precision': 0.205, 'eval_recall': 0.3106060606060606, 'eval_f1': 0.2469879518072289, 'eval_accuracy': 0.7915650406504066, 'eval_runtime': 0.5007, 'eval_samples_per_second': 79.885, 'eval_steps_per_second': 5.991, 'epoch': 3.4}
{'loss': 0.4155, 'learning_rate': 3.0158730158730158e-05, 'epoch': 3.97}
              precision    recall  f1-score   support

       NSWER       0.14      0.38      0.20        40
     UESTION       0.35      0.29      0.32        92

   micro avg       0.23      0.32      0.26       132
   macro avg       0.24      0.33      0.26       132
weighted avg       0.29      0.32      0.28       132

{'eval_loss': 0.5483952760696411, 'eval_precision': 0.22580645161290322, 'eval_recall': 0.3181818181818182, 'eval_f1': 0.2641509433962264, 'eval_accuracy': 0.7740853658536585, 'eval_runtime': 0.5001, 'eval_samples_per_second': 79.979, 'eval_steps_per_second': 5.998, 'epoch': 3.97}
{'train_runtime': 331.1507, 'train_samples_per_second': 106.417, 'train_steps_per_second': 13.317, 'train_loss': 0.6079509538922991, 'epoch': 3.97}
              precision    recall  f1-score   support

       NSWER       0.13      0.32      0.19        79
     UESTION       0.50      0.56      0.53       109

   micro avg       0.28      0.46      0.35       188
   macro avg       0.32      0.44      0.36       188
weighted avg       0.35      0.46      0.39       188

{'epoch': 3.97,
 'eval_accuracy': 0.8411313586153522,
 'eval_f1': 0.34607645875251514,
 'eval_loss': 0.38084715604782104,
 'eval_precision': 0.2783171521035599,
 'eval_recall': 0.4574468085106383,
 'eval_runtime': 0.7785,
 'eval_samples_per_second': 77.072,
 'eval_steps_per_second': 5.138}
Accuracy: 0.8411313586153522
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	5e-5	num_train_epochs	10	END 4753310: Fri 13 Oct 2023 12:44:49 PM EEST
