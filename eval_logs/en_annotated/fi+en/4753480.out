START 4753480: Fri 13 Oct 2023 12:46:17 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/annotated/cleaned2_train_annotated_dataset.jsonl'], test='../../data/qa_token_classification/annotated/en_test_dataset.jsonl', dev='../../data/qa_token_classification/annotated/en_dev_dataset.jsonl', batch=8, epochs=10, lr=1e-05, save=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 40
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 60
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 1.1081, 'learning_rate': 8.076923076923077e-06, 'epoch': 1.92}
              precision    recall  f1-score   support

       NSWER       0.00      0.03      0.00        40
     UESTION       0.00      0.00      0.00        92

   micro avg       0.00      0.01      0.00       132
   macro avg       0.00      0.01      0.00       132
weighted avg       0.00      0.01      0.00       132

{'eval_loss': 1.0303459167480469, 'eval_precision': 0.0008278145695364238, 'eval_recall': 0.007575757575757576, 'eval_f1': 0.0014925373134328356, 'eval_accuracy': 0.4274390243902439, 'eval_runtime': 0.5591, 'eval_samples_per_second': 71.539, 'eval_steps_per_second': 5.365, 'epoch': 1.92}
{'loss': 0.9471, 'learning_rate': 6.153846153846155e-06, 'epoch': 3.85}
              precision    recall  f1-score   support

       NSWER       0.00      0.07      0.01        40
     UESTION       0.00      0.00      0.00        92

   micro avg       0.00      0.02      0.01       132
   macro avg       0.00      0.04      0.00       132
weighted avg       0.00      0.02      0.00       132

{'eval_loss': 0.9083185195922852, 'eval_precision': 0.0035842293906810036, 'eval_recall': 0.022727272727272728, 'eval_f1': 0.006191950464396285, 'eval_accuracy': 0.5515243902439024, 'eval_runtime': 0.5051, 'eval_samples_per_second': 79.191, 'eval_steps_per_second': 5.939, 'epoch': 3.85}
{'loss': 0.7739, 'learning_rate': 4.230769230769231e-06, 'epoch': 5.77}
              precision    recall  f1-score   support

       NSWER       0.00      0.07      0.01        40
     UESTION       0.00      0.00      0.00        92

   micro avg       0.00      0.02      0.01       132
   macro avg       0.00      0.04      0.00       132
weighted avg       0.00      0.02      0.00       132

{'eval_loss': 0.8771395683288574, 'eval_precision': 0.004225352112676056, 'eval_recall': 0.022727272727272728, 'eval_f1': 0.007125890736342042, 'eval_accuracy': 0.5646341463414634, 'eval_runtime': 0.4974, 'eval_samples_per_second': 80.419, 'eval_steps_per_second': 6.031, 'epoch': 5.77}
{'loss': 0.631, 'learning_rate': 2.307692307692308e-06, 'epoch': 7.69}
              precision    recall  f1-score   support

       NSWER       0.01      0.07      0.01        40
     UESTION       0.00      0.00      0.00        92

   micro avg       0.00      0.02      0.01       132
   macro avg       0.00      0.04      0.00       132
weighted avg       0.00      0.02      0.00       132

{'eval_loss': 0.826564610004425, 'eval_precision': 0.004132231404958678, 'eval_recall': 0.022727272727272728, 'eval_f1': 0.006993006993006993, 'eval_accuracy': 0.6050813008130081, 'eval_runtime': 0.4947, 'eval_samples_per_second': 80.86, 'eval_steps_per_second': 6.064, 'epoch': 7.69}
{'loss': 0.5269, 'learning_rate': 3.846153846153847e-07, 'epoch': 9.62}
              precision    recall  f1-score   support

       NSWER       0.01      0.07      0.01        40
     UESTION       0.00      0.00      0.00        92

   micro avg       0.00      0.02      0.01       132
   macro avg       0.00      0.04      0.01       132
weighted avg       0.00      0.02      0.00       132

{'eval_loss': 0.8201490640640259, 'eval_precision': 0.00410958904109589, 'eval_recall': 0.022727272727272728, 'eval_f1': 0.006960556844547563, 'eval_accuracy': 0.6055894308943089, 'eval_runtime': 0.4921, 'eval_samples_per_second': 81.283, 'eval_steps_per_second': 6.096, 'epoch': 9.62}
{'train_runtime': 42.4175, 'train_samples_per_second': 23.575, 'train_steps_per_second': 3.065, 'train_loss': 0.7830644515844492, 'epoch': 10.0}
              precision    recall  f1-score   support

       NSWER       0.01      0.09      0.02        79
     UESTION       0.00      0.00      0.00       109

   micro avg       0.01      0.04      0.01       188
   macro avg       0.00      0.04      0.01       188
weighted avg       0.00      0.04      0.01       188

{'epoch': 10.0,
 'eval_accuracy': 0.5871385351438824,
 'eval_f1': 0.012152777777777778,
 'eval_loss': 0.7965266704559326,
 'eval_precision': 0.007261410788381743,
 'eval_recall': 0.03723404255319149,
 'eval_runtime': 0.7372,
 'eval_samples_per_second': 81.384,
 'eval_steps_per_second': 5.426}
Accuracy: 0.5871385351438824
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	1e-5	num_train_epochs	10	END 4753480: Fri 13 Oct 2023 12:47:40 PM EEST
