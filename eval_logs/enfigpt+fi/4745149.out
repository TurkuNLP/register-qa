START 4745149: Thu 12 Oct 2023 11:56:35 AM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl', '../../data/qa_token_classification/annotated/train_annotated_dataset.jsonl'], test='../../data/qa_token_classification/annotated/test_annotated_dataset.jsonl', dev='../../data/qa_token_classification/annotated/dev_annotated_dataset.jsonl', batch=8, epochs=10, lr=1e-05, save=None, dataset=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
in dictionary: 2
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138182
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138182
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 50
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 68
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.1536, 'learning_rate': 9.855265443177214e-06, 'epoch': 0.14}
              precision    recall  f1-score   support

       NSWER       0.00      0.00      0.00        40
     UESTION       0.02      0.02      0.02        46

   micro avg       0.02      0.01      0.01        86
   macro avg       0.01      0.01      0.01        86
weighted avg       0.01      0.01      0.01        86

{'eval_loss': 1.200415015220642, 'eval_precision': 0.01694915254237288, 'eval_recall': 0.011627906976744186, 'eval_f1': 0.013793103448275862, 'eval_accuracy': 0.5005062009617818, 'eval_runtime': 0.5122, 'eval_samples_per_second': 97.617, 'eval_steps_per_second': 7.809, 'epoch': 0.14}
{'loss': 0.0863, 'learning_rate': 9.710530886354427e-06, 'epoch': 0.29}
              precision    recall  f1-score   support

       NSWER       0.05      0.15      0.07        40
     UESTION       0.08      0.15      0.11        46

   micro avg       0.06      0.15      0.09        86
   macro avg       0.07      0.15      0.09        86
weighted avg       0.07      0.15      0.09        86

{'eval_loss': 0.7589806914329529, 'eval_precision': 0.06190476190476191, 'eval_recall': 0.1511627906976744, 'eval_f1': 0.08783783783783784, 'eval_accuracy': 0.6583143507972665, 'eval_runtime': 1.5784, 'eval_samples_per_second': 31.678, 'eval_steps_per_second': 2.534, 'epoch': 0.29}
{'loss': 0.0765, 'learning_rate': 9.56579632953164e-06, 'epoch': 0.43}
              precision    recall  f1-score   support

       NSWER       0.19      0.35      0.25        40
     UESTION       0.40      0.41      0.41        46

   micro avg       0.28      0.38      0.32        86
   macro avg       0.30      0.38      0.33        86
weighted avg       0.31      0.38      0.33        86

{'eval_loss': 0.7773111462593079, 'eval_precision': 0.2773109243697479, 'eval_recall': 0.38372093023255816, 'eval_f1': 0.32195121951219513, 'eval_accuracy': 0.7248797772715768, 'eval_runtime': 0.5291, 'eval_samples_per_second': 94.495, 'eval_steps_per_second': 7.56, 'epoch': 0.43}
{'loss': 0.0695, 'learning_rate': 9.421061772708852e-06, 'epoch': 0.58}
              precision    recall  f1-score   support

       NSWER       0.13      0.30      0.18        40
     UESTION       0.25      0.48      0.33        46

   micro avg       0.19      0.40      0.26        86
   macro avg       0.19      0.39      0.26        86
weighted avg       0.19      0.40      0.26        86

{'eval_loss': 0.5530593395233154, 'eval_precision': 0.18994413407821228, 'eval_recall': 0.3953488372093023, 'eval_f1': 0.25660377358490566, 'eval_accuracy': 0.7352568969881043, 'eval_runtime': 1.5625, 'eval_samples_per_second': 31.999, 'eval_steps_per_second': 2.56, 'epoch': 0.58}
{'loss': 0.0636, 'learning_rate': 9.276327215886066e-06, 'epoch': 0.72}
              precision    recall  f1-score   support

       NSWER       0.09      0.17      0.12        40
     UESTION       0.29      0.39      0.33        46

   micro avg       0.18      0.29      0.22        86
   macro avg       0.19      0.28      0.22        86
weighted avg       0.19      0.29      0.23        86

{'eval_loss': 0.6076956987380981, 'eval_precision': 0.1773049645390071, 'eval_recall': 0.29069767441860467, 'eval_f1': 0.22026431718061676, 'eval_accuracy': 0.7510756770437864, 'eval_runtime': 1.5523, 'eval_samples_per_second': 32.21, 'eval_steps_per_second': 2.577, 'epoch': 0.72}
{'loss': 0.0638, 'learning_rate': 9.131592659063279e-06, 'epoch': 0.87}
              precision    recall  f1-score   support

       NSWER       0.10      0.25      0.14        40
     UESTION       0.34      0.61      0.43        46

   micro avg       0.20      0.44      0.28        86
   macro avg       0.22      0.43      0.29        86
weighted avg       0.23      0.44      0.30        86

{'eval_loss': 0.5627966523170471, 'eval_precision': 0.20430107526881722, 'eval_recall': 0.4418604651162791, 'eval_f1': 0.27941176470588236, 'eval_accuracy': 0.7198177676537585, 'eval_runtime': 0.5868, 'eval_samples_per_second': 85.204, 'eval_steps_per_second': 6.816, 'epoch': 0.87}
{'loss': 0.0591, 'learning_rate': 8.986858102240492e-06, 'epoch': 1.01}
              precision    recall  f1-score   support

       NSWER       0.29      0.53      0.37        40
     UESTION       0.28      0.59      0.38        46

   micro avg       0.28      0.56      0.38        86
   macro avg       0.28      0.56      0.37        86
weighted avg       0.28      0.56      0.37        86

{'eval_loss': 0.4447375535964966, 'eval_precision': 0.2823529411764706, 'eval_recall': 0.5581395348837209, 'eval_f1': 0.375, 'eval_accuracy': 0.8228296633763604, 'eval_runtime': 0.5439, 'eval_samples_per_second': 91.929, 'eval_steps_per_second': 7.354, 'epoch': 1.01}
{'loss': 0.0484, 'learning_rate': 8.842123545417704e-06, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.21      0.42      0.28        40
     UESTION       0.30      0.35      0.32        46

   micro avg       0.24      0.38      0.30        86
   macro avg       0.25      0.39      0.30        86
weighted avg       0.26      0.38      0.30        86

{'eval_loss': 0.6057240962982178, 'eval_precision': 0.24444444444444444, 'eval_recall': 0.38372093023255816, 'eval_f1': 0.2986425339366516, 'eval_accuracy': 0.7690458111870413, 'eval_runtime': 0.5316, 'eval_samples_per_second': 94.058, 'eval_steps_per_second': 7.525, 'epoch': 1.16}
{'loss': 0.0489, 'learning_rate': 8.697388988594919e-06, 'epoch': 1.3}
              precision    recall  f1-score   support

       NSWER       0.19      0.38      0.25        40
     UESTION       0.24      0.43      0.31        46

   micro avg       0.21      0.41      0.28        86
   macro avg       0.21      0.40      0.28        86
weighted avg       0.22      0.41      0.28        86

{'eval_loss': 0.6287068128585815, 'eval_precision': 0.2147239263803681, 'eval_recall': 0.4069767441860465, 'eval_f1': 0.28112449799196787, 'eval_accuracy': 0.7547456340167046, 'eval_runtime': 0.5413, 'eval_samples_per_second': 92.363, 'eval_steps_per_second': 7.389, 'epoch': 1.3}
{'loss': 0.0489, 'learning_rate': 8.55265443177213e-06, 'epoch': 1.45}
              precision    recall  f1-score   support

       NSWER       0.18      0.38      0.24        40
     UESTION       0.39      0.48      0.43        46

   micro avg       0.26      0.43      0.32        86
   macro avg       0.28      0.43      0.33        86
weighted avg       0.29      0.43      0.34        86

{'eval_loss': 0.5374077558517456, 'eval_precision': 0.2605633802816901, 'eval_recall': 0.43023255813953487, 'eval_f1': 0.3245614035087719, 'eval_accuracy': 0.7841052898000507, 'eval_runtime': 0.5305, 'eval_samples_per_second': 94.254, 'eval_steps_per_second': 7.54, 'epoch': 1.45}
{'loss': 0.0447, 'learning_rate': 8.407919874949344e-06, 'epoch': 1.59}
              precision    recall  f1-score   support

       NSWER       0.26      0.47      0.34        40
     UESTION       0.49      0.54      0.52        46

   micro avg       0.35      0.51      0.42        86
   macro avg       0.38      0.51      0.43        86
weighted avg       0.38      0.51      0.43        86

{'eval_loss': 0.4961135983467102, 'eval_precision': 0.3548387096774194, 'eval_recall': 0.5116279069767442, 'eval_f1': 0.41904761904761906, 'eval_accuracy': 0.7772715768159959, 'eval_runtime': 1.5597, 'eval_samples_per_second': 32.057, 'eval_steps_per_second': 2.565, 'epoch': 1.59}
{'loss': 0.0505, 'learning_rate': 8.263185318126557e-06, 'epoch': 1.74}
              precision    recall  f1-score   support

       NSWER       0.26      0.42      0.32        40
     UESTION       0.27      0.48      0.35        46

   micro avg       0.27      0.45      0.34        86
   macro avg       0.27      0.45      0.34        86
weighted avg       0.27      0.45      0.34        86

{'eval_loss': 0.5065115690231323, 'eval_precision': 0.2671232876712329, 'eval_recall': 0.45348837209302323, 'eval_f1': 0.33620689655172414, 'eval_accuracy': 0.7730954188812958, 'eval_runtime': 0.5724, 'eval_samples_per_second': 87.345, 'eval_steps_per_second': 6.988, 'epoch': 1.74}
{'train_runtime': 5260.2447, 'train_samples_per_second': 262.691, 'train_steps_per_second': 32.837, 'train_loss': 0.0678118537902832, 'epoch': 1.74}
              precision    recall  f1-score   support

       NSWER       0.34      0.53      0.41        59
     UESTION       0.33      0.58      0.42        73

   micro avg       0.33      0.55      0.42       132
   macro avg       0.34      0.55      0.42       132
weighted avg       0.33      0.55      0.42       132

{'epoch': 1.74,
 'eval_accuracy': 0.851136042236259,
 'eval_f1': 0.41714285714285715,
 'eval_loss': 0.3498917520046234,
 'eval_precision': 0.3348623853211009,
 'eval_recall': 0.553030303030303,
 'eval_runtime': 0.7953,
 'eval_samples_per_second': 85.501,
 'eval_steps_per_second': 6.287}
Accuracy: 0.851136042236259
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	1e-5	num_train_epochs	10	END 4745149: Thu 12 Oct 2023 01:29:12 PM EEST
