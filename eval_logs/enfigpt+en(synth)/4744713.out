START 4744713: Thu 12 Oct 2023 11:01:07 AM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/train_annotated_dataset.jsonl', '../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl'], test='../../data/qa_token_classification/dataset_punct2', dev='../../data/qa_token_classification/dataset_punct2', batch=8, epochs=10, lr=3e-05, save=None, dataset=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
in dictionary: 2
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138182
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138182
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.133, 'learning_rate': 2.9565796329531642e-05, 'epoch': 0.14}
              precision    recall  f1-score   support

       NSWER       0.67      0.82      0.74      1659
     UESTION       0.67      0.81      0.73      1683

   micro avg       0.67      0.82      0.74      3342
   macro avg       0.67      0.82      0.74      3342
weighted avg       0.67      0.82      0.74      3342

{'eval_loss': 0.13472306728363037, 'eval_precision': 0.6687086498407253, 'eval_recall': 0.8165769000598444, 'eval_f1': 0.7352822309039472, 'eval_accuracy': 0.9650938733218971, 'eval_runtime': 25.2665, 'eval_samples_per_second': 66.61, 'eval_steps_per_second': 4.195, 'epoch': 0.14}
{'loss': 0.0937, 'learning_rate': 2.9131592659063277e-05, 'epoch': 0.29}
              precision    recall  f1-score   support

       NSWER       0.72      0.84      0.78      1659
     UESTION       0.70      0.80      0.75      1683

   micro avg       0.71      0.82      0.76      3342
   macro avg       0.71      0.82      0.76      3342
weighted avg       0.71      0.82      0.76      3342

{'eval_loss': 0.10654780268669128, 'eval_precision': 0.7079783113865221, 'eval_recall': 0.8204667863554758, 'eval_f1': 0.7600831600831601, 'eval_accuracy': 0.9705520856186018, 'eval_runtime': 24.1032, 'eval_samples_per_second': 69.825, 'eval_steps_per_second': 4.398, 'epoch': 0.29}
{'loss': 0.0871, 'learning_rate': 2.869738898859492e-05, 'epoch': 0.43}
              precision    recall  f1-score   support

       NSWER       0.81      0.87      0.84      1659
     UESTION       0.81      0.86      0.83      1683

   micro avg       0.81      0.86      0.84      3342
   macro avg       0.81      0.86      0.84      3342
weighted avg       0.81      0.86      0.84      3342

{'eval_loss': 0.08151663839817047, 'eval_precision': 0.8092436974789916, 'eval_recall': 0.8644524236983842, 'eval_f1': 0.8359374999999999, 'eval_accuracy': 0.977553927930452, 'eval_runtime': 23.194, 'eval_samples_per_second': 72.562, 'eval_steps_per_second': 4.57, 'epoch': 0.43}
{'loss': 0.0768, 'learning_rate': 2.8263185318126557e-05, 'epoch': 0.58}
              precision    recall  f1-score   support

       NSWER       0.77      0.86      0.81      1659
     UESTION       0.77      0.86      0.81      1683

   micro avg       0.77      0.86      0.81      3342
   macro avg       0.77      0.86      0.81      3342
weighted avg       0.77      0.86      0.81      3342

{'eval_loss': 0.10928787291049957, 'eval_precision': 0.7682828824002143, 'eval_recall': 0.8581687612208259, 'eval_f1': 0.8107420494699645, 'eval_accuracy': 0.9694815887759067, 'eval_runtime': 24.8789, 'eval_samples_per_second': 67.648, 'eval_steps_per_second': 4.261, 'epoch': 0.58}
{'loss': 0.0676, 'learning_rate': 2.78289816476582e-05, 'epoch': 0.72}
              precision    recall  f1-score   support

       NSWER       0.79      0.87      0.83      1659
     UESTION       0.78      0.86      0.82      1683

   micro avg       0.79      0.87      0.82      3342
   macro avg       0.79      0.87      0.82      3342
weighted avg       0.79      0.87      0.82      3342

{'eval_loss': 0.06123988330364227, 'eval_precision': 0.7852494577006508, 'eval_recall': 0.8665469778575703, 'eval_f1': 0.8238975817923186, 'eval_accuracy': 0.9800464674925792, 'eval_runtime': 24.0458, 'eval_samples_per_second': 69.992, 'eval_steps_per_second': 4.408, 'epoch': 0.72}
{'loss': 0.0667, 'learning_rate': 2.7394777977189834e-05, 'epoch': 0.87}
              precision    recall  f1-score   support

       NSWER       0.83      0.89      0.86      1659
     UESTION       0.84      0.89      0.86      1683

   micro avg       0.83      0.89      0.86      3342
   macro avg       0.83      0.89      0.86      3342
weighted avg       0.83      0.89      0.86      3342

{'eval_loss': 0.07375094294548035, 'eval_precision': 0.8344981828347777, 'eval_recall': 0.8931777378815081, 'eval_f1': 0.8628414510767451, 'eval_accuracy': 0.9796737759991965, 'eval_runtime': 23.0063, 'eval_samples_per_second': 73.154, 'eval_steps_per_second': 4.607, 'epoch': 0.87}
{'loss': 0.0709, 'learning_rate': 2.6960574306721475e-05, 'epoch': 1.01}
              precision    recall  f1-score   support

       NSWER       0.84      0.89      0.87      1659
     UESTION       0.83      0.88      0.86      1683

   micro avg       0.84      0.89      0.86      3342
   macro avg       0.84      0.89      0.86      3342
weighted avg       0.84      0.89      0.86      3342

{'eval_loss': 0.11219038814306259, 'eval_precision': 0.8361996053002537, 'eval_recall': 0.8874925194494315, 'eval_f1': 0.8610828857599071, 'eval_accuracy': 0.974397944646062, 'eval_runtime': 24.0493, 'eval_samples_per_second': 69.981, 'eval_steps_per_second': 4.408, 'epoch': 1.01}
{'loss': 0.0597, 'learning_rate': 2.6526370636253113e-05, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.83      0.89      0.86      1659
     UESTION       0.83      0.89      0.86      1683

   micro avg       0.83      0.89      0.86      3342
   macro avg       0.83      0.89      0.86      3342
weighted avg       0.83      0.89      0.86      3342

{'eval_loss': 0.07865175604820251, 'eval_precision': 0.8338020247469067, 'eval_recall': 0.8871932974266906, 'eval_f1': 0.8596694694114236, 'eval_accuracy': 0.9788094489187982, 'eval_runtime': 24.128, 'eval_samples_per_second': 69.753, 'eval_steps_per_second': 4.393, 'epoch': 1.16}
{'loss': 0.0549, 'learning_rate': 2.609216696578475e-05, 'epoch': 1.3}
              precision    recall  f1-score   support

       NSWER       0.82      0.89      0.85      1659
     UESTION       0.81      0.88      0.85      1683

   micro avg       0.81      0.89      0.85      3342
   macro avg       0.81      0.89      0.85      3342
weighted avg       0.81      0.89      0.85      3342

{'eval_loss': 0.06531600654125214, 'eval_precision': 0.8147842813959879, 'eval_recall': 0.8871932974266906, 'eval_f1': 0.849448503079788, 'eval_accuracy': 0.980038537886337, 'eval_runtime': 24.169, 'eval_samples_per_second': 69.635, 'eval_steps_per_second': 4.386, 'epoch': 1.3}
{'loss': 0.0547, 'learning_rate': 2.565796329531639e-05, 'epoch': 1.45}
              precision    recall  f1-score   support

       NSWER       0.87      0.91      0.89      1659
     UESTION       0.86      0.90      0.88      1683

   micro avg       0.87      0.90      0.88      3342
   macro avg       0.87      0.90      0.88      3342
weighted avg       0.87      0.90      0.88      3342

{'eval_loss': 0.07433152943849564, 'eval_precision': 0.8678756476683938, 'eval_recall': 0.9021543985637342, 'eval_f1': 0.8846830985915493, 'eval_accuracy': 0.9803821541568317, 'eval_runtime': 23.6449, 'eval_samples_per_second': 71.178, 'eval_steps_per_second': 4.483, 'epoch': 1.45}
{'train_runtime': 5297.6994, 'train_samples_per_second': 260.834, 'train_steps_per_second': 32.605, 'train_loss': 0.07649541137695312, 'epoch': 1.45}
              precision    recall  f1-score   support

       NSWER       0.81      0.88      0.84      5623
     UESTION       0.80      0.87      0.83      5693

   micro avg       0.80      0.87      0.84     11316
   macro avg       0.80      0.87      0.84     11316
weighted avg       0.80      0.87      0.84     11316

{'epoch': 1.45,
 'eval_accuracy': 0.9808512689404478,
 'eval_f1': 0.8359308826020667,
 'eval_loss': 0.05680132284760475,
 'eval_precision': 0.8026187378009109,
 'eval_recall': 0.8721279604100389,
 'eval_runtime': 78.3397,
 'eval_samples_per_second': 72.671,
 'eval_steps_per_second': 4.544}
Accuracy: 0.9808512689404478
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	3e-5	num_train_epochs	10	END 4744713: Thu 12 Oct 2023 12:36:27 PM EEST
