START 4744716: Thu 12 Oct 2023 11:01:19 AM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/train_annotated_dataset.jsonl', '../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl'], test='../../data/qa_token_classification/dataset_punct2', dev='../../data/qa_token_classification/dataset_punct2', batch=8, epochs=10, lr=1e-05, save=None, dataset=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
in dictionary: 2
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138182
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138182
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.1594, 'learning_rate': 9.855265443177214e-06, 'epoch': 0.14}
              precision    recall  f1-score   support

       NSWER       0.61      0.80      0.69      1659
     UESTION       0.61      0.80      0.69      1683

   micro avg       0.61      0.80      0.69      3342
   macro avg       0.61      0.80      0.69      3342
weighted avg       0.61      0.80      0.69      3342

{'eval_loss': 0.1277570128440857, 'eval_precision': 0.6097728836889195, 'eval_recall': 0.7953321364452424, 'eval_f1': 0.6902999610440204, 'eval_accuracy': 0.9638039907065015, 'eval_runtime': 24.3794, 'eval_samples_per_second': 69.034, 'eval_steps_per_second': 4.348, 'epoch': 0.14}
{'loss': 0.0892, 'learning_rate': 9.710530886354427e-06, 'epoch': 0.29}
              precision    recall  f1-score   support

       NSWER       0.75      0.84      0.79      1659
     UESTION       0.76      0.84      0.80      1683

   micro avg       0.75      0.84      0.79      3342
   macro avg       0.75      0.84      0.79      3342
weighted avg       0.75      0.84      0.79      3342

{'eval_loss': 0.08814261853694916, 'eval_precision': 0.7511372758897511, 'eval_recall': 0.8399162178336326, 'eval_f1': 0.7930498658002544, 'eval_accuracy': 0.9756085311990358, 'eval_runtime': 24.199, 'eval_samples_per_second': 69.548, 'eval_steps_per_second': 4.38, 'epoch': 0.29}
{'loss': 0.074, 'learning_rate': 9.56579632953164e-06, 'epoch': 0.43}
              precision    recall  f1-score   support

       NSWER       0.76      0.86      0.81      1659
     UESTION       0.76      0.85      0.80      1683

   micro avg       0.76      0.86      0.81      3342
   macro avg       0.76      0.86      0.81      3342
weighted avg       0.76      0.86      0.81      3342

{'eval_loss': 0.08671606332063675, 'eval_precision': 0.7620441841895129, 'eval_recall': 0.8566726511071214, 'eval_f1': 0.8065924778137765, 'eval_accuracy': 0.9775988623658245, 'eval_runtime': 24.1002, 'eval_samples_per_second': 69.834, 'eval_steps_per_second': 4.398, 'epoch': 0.43}
{'loss': 0.0717, 'learning_rate': 9.421061772708852e-06, 'epoch': 0.58}
              precision    recall  f1-score   support

       NSWER       0.82      0.88      0.85      1659
     UESTION       0.82      0.88      0.85      1683

   micro avg       0.82      0.88      0.85      3342
   macro avg       0.82      0.88      0.85      3342
weighted avg       0.82      0.88      0.85      3342

{'eval_loss': 0.09254653751850128, 'eval_precision': 0.8225083986562151, 'eval_recall': 0.879114302812687, 'eval_f1': 0.8498698293317906, 'eval_accuracy': 0.9773662605827204, 'eval_runtime': 24.2674, 'eval_samples_per_second': 69.352, 'eval_steps_per_second': 4.368, 'epoch': 0.58}
{'loss': 0.0746, 'learning_rate': 9.276327215886066e-06, 'epoch': 0.72}
              precision    recall  f1-score   support

       NSWER       0.82      0.89      0.85      1659
     UESTION       0.82      0.88      0.85      1683

   micro avg       0.82      0.89      0.85      3342
   macro avg       0.82      0.89      0.85      3342
weighted avg       0.82      0.89      0.85      3342

{'eval_loss': 0.07167594879865646, 'eval_precision': 0.8161521499448732, 'eval_recall': 0.8859964093357271, 'eval_f1': 0.8496413199426112, 'eval_accuracy': 0.9785847767419362, 'eval_runtime': 24.2225, 'eval_samples_per_second': 69.481, 'eval_steps_per_second': 4.376, 'epoch': 0.72}
{'loss': 0.0654, 'learning_rate': 9.131592659063279e-06, 'epoch': 0.87}
              precision    recall  f1-score   support

       NSWER       0.84      0.89      0.86      1659
     UESTION       0.84      0.88      0.86      1683

   micro avg       0.84      0.89      0.86      3342
   macro avg       0.84      0.89      0.86      3342
weighted avg       0.84      0.89      0.86      3342

{'eval_loss': 0.10515382885932922, 'eval_precision': 0.8387553041018387, 'eval_recall': 0.8871932974266906, 'eval_f1': 0.8622946052057583, 'eval_accuracy': 0.9765019335023221, 'eval_runtime': 24.0951, 'eval_samples_per_second': 69.848, 'eval_steps_per_second': 4.399, 'epoch': 0.87}
{'loss': 0.0629, 'learning_rate': 8.986858102240492e-06, 'epoch': 1.01}
              precision    recall  f1-score   support

       NSWER       0.85      0.90      0.87      1659
     UESTION       0.85      0.90      0.88      1683

   micro avg       0.85      0.90      0.87      3342
   macro avg       0.85      0.90      0.87      3342
weighted avg       0.85      0.90      0.87      3342

{'eval_loss': 0.0981530100107193, 'eval_precision': 0.8529160739687055, 'eval_recall': 0.8970676241771395, 'eval_f1': 0.8744348840600846, 'eval_accuracy': 0.9816508911555816, 'eval_runtime': 24.2527, 'eval_samples_per_second': 69.394, 'eval_steps_per_second': 4.371, 'epoch': 1.01}
{'loss': 0.048, 'learning_rate': 8.842123545417704e-06, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.85      0.90      0.88      1659
     UESTION       0.85      0.89      0.87      1683

   micro avg       0.85      0.90      0.87      3342
   macro avg       0.85      0.90      0.87      3342
weighted avg       0.85      0.90      0.87      3342

{'eval_loss': 0.09055201709270477, 'eval_precision': 0.8486730660643704, 'eval_recall': 0.8994614003590664, 'eval_f1': 0.873329459616502, 'eval_accuracy': 0.9811539691644046, 'eval_runtime': 24.4852, 'eval_samples_per_second': 68.736, 'eval_steps_per_second': 4.329, 'epoch': 1.16}
{'loss': 0.0542, 'learning_rate': 8.697388988594919e-06, 'epoch': 1.3}
              precision    recall  f1-score   support

       NSWER       0.87      0.91      0.89      1659
     UESTION       0.87      0.89      0.88      1683

   micro avg       0.87      0.90      0.88      3342
   macro avg       0.87      0.90      0.88      3342
weighted avg       0.87      0.90      0.88      3342

{'eval_loss': 0.0806582123041153, 'eval_precision': 0.8702201622247973, 'eval_recall': 0.8988629563135847, 'eval_f1': 0.8843096850161908, 'eval_accuracy': 0.9813204908954904, 'eval_runtime': 25.6548, 'eval_samples_per_second': 65.602, 'eval_steps_per_second': 4.132, 'epoch': 1.3}
{'loss': 0.0501, 'learning_rate': 8.55265443177213e-06, 'epoch': 1.45}
              precision    recall  f1-score   support

       NSWER       0.86      0.91      0.88      1659
     UESTION       0.86      0.91      0.88      1683

   micro avg       0.86      0.91      0.88      3342
   macro avg       0.86      0.91      0.88      3342
weighted avg       0.86      0.91      0.88      3342

{'eval_loss': 0.07348576933145523, 'eval_precision': 0.8589997174343035, 'eval_recall': 0.9096349491322562, 'eval_f1': 0.8835925010899578, 'eval_accuracy': 0.9833583996997323, 'eval_runtime': 24.0416, 'eval_samples_per_second': 70.004, 'eval_steps_per_second': 4.409, 'epoch': 1.45}
{'train_runtime': 5066.9421, 'train_samples_per_second': 272.713, 'train_steps_per_second': 34.09, 'train_loss': 0.07494072326660156, 'epoch': 1.45}
              precision    recall  f1-score   support

       NSWER       0.81      0.89      0.85      5623
     UESTION       0.81      0.88      0.84      5693

   micro avg       0.81      0.88      0.84     11316
   macro avg       0.81      0.88      0.84     11316
weighted avg       0.81      0.88      0.84     11316

{'epoch': 1.45,
 'eval_accuracy': 0.9815550819926531,
 'eval_f1': 0.8430512193063876,
 'eval_loss': 0.06227773427963257,
 'eval_precision': 0.806636525108994,
 'eval_recall': 0.8829091551785083,
 'eval_runtime': 82.4047,
 'eval_samples_per_second': 69.086,
 'eval_steps_per_second': 4.32}
Accuracy: 0.9815550819926531
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	1e-5	num_train_epochs	10	END 4744716: Thu 12 Oct 2023 12:33:59 PM EEST
