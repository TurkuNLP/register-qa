START 4744639: Thu 12 Oct 2023 10:57:45 AM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2'], test='../../data/qa_token_classification/dataset_punct2', dev='../../data/qa_token_classification/dataset_punct2', batch=8, epochs=10, lr=1e-05, save=None, dataset=None)
0
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.1241, 'learning_rate': 9.851482207568468e-06, 'epoch': 0.15}
              precision    recall  f1-score   support

       NSWER       0.67      0.84      0.75      1659
     UESTION       0.67      0.82      0.73      1683

   micro avg       0.67      0.83      0.74      3342
   macro avg       0.67      0.83      0.74      3342
weighted avg       0.67      0.83      0.74      3342

{'eval_loss': 0.11872885376214981, 'eval_precision': 0.6707168894289186, 'eval_recall': 0.8258527827648114, 'eval_f1': 0.7402440659782754, 'eval_accuracy': 0.9661379381437849, 'eval_runtime': 24.0092, 'eval_samples_per_second': 70.098, 'eval_steps_per_second': 4.415, 'epoch': 0.15}
{'loss': 0.0706, 'learning_rate': 9.702964415136934e-06, 'epoch': 0.3}
              precision    recall  f1-score   support

       NSWER       0.78      0.87      0.82      1659
     UESTION       0.79      0.86      0.82      1683

   micro avg       0.79      0.87      0.82      3342
   macro avg       0.79      0.87      0.82      3342
weighted avg       0.79      0.87      0.82      3342

{'eval_loss': 0.1062273159623146, 'eval_precision': 0.7856560717196414, 'eval_recall': 0.8653500897666068, 'eval_f1': 0.8235796668090559, 'eval_accuracy': 0.9754605118825149, 'eval_runtime': 24.1093, 'eval_samples_per_second': 69.807, 'eval_steps_per_second': 4.397, 'epoch': 0.3}
{'loss': 0.0572, 'learning_rate': 9.554446622705401e-06, 'epoch': 0.45}
              precision    recall  f1-score   support

       NSWER       0.82      0.88      0.85      1659
     UESTION       0.82      0.88      0.85      1683

   micro avg       0.82      0.88      0.85      3342
   macro avg       0.82      0.88      0.85      3342
weighted avg       0.82      0.88      0.85      3342

{'eval_loss': 0.09837876260280609, 'eval_precision': 0.8242865137101287, 'eval_recall': 0.881508078994614, 'eval_f1': 0.8519375361480626, 'eval_accuracy': 0.9760314435319524, 'eval_runtime': 24.5071, 'eval_samples_per_second': 68.674, 'eval_steps_per_second': 4.325, 'epoch': 0.45}
{'loss': 0.0588, 'learning_rate': 9.405928830273868e-06, 'epoch': 0.59}
              precision    recall  f1-score   support

       NSWER       0.83      0.89      0.86      1659
     UESTION       0.84      0.89      0.86      1683

   micro avg       0.84      0.89      0.86      3342
   macro avg       0.84      0.89      0.86      3342
weighted avg       0.84      0.89      0.86      3342

{'eval_loss': 0.0704227089881897, 'eval_precision': 0.835063113604488, 'eval_recall': 0.8907839616995811, 'eval_f1': 0.8620240335891124, 'eval_accuracy': 0.9804773094317379, 'eval_runtime': 24.0081, 'eval_samples_per_second': 70.101, 'eval_steps_per_second': 4.415, 'epoch': 0.59}
{'loss': 0.0503, 'learning_rate': 9.257411037842334e-06, 'epoch': 0.74}
              precision    recall  f1-score   support

       NSWER       0.85      0.89      0.87      1659
     UESTION       0.85      0.89      0.87      1683

   micro avg       0.85      0.89      0.87      3342
   macro avg       0.85      0.89      0.87      3342
weighted avg       0.85      0.89      0.87      3342

{'eval_loss': 0.0954718142747879, 'eval_precision': 0.8483723586521987, 'eval_recall': 0.8889886295631358, 'eval_f1': 0.8682057276446522, 'eval_accuracy': 0.9794781790452225, 'eval_runtime': 24.1758, 'eval_samples_per_second': 69.615, 'eval_steps_per_second': 4.385, 'epoch': 0.74}
{'loss': 0.0463, 'learning_rate': 9.108893245410801e-06, 'epoch': 0.89}
              precision    recall  f1-score   support

       NSWER       0.90      0.92      0.91      1659
     UESTION       0.90      0.91      0.90      1683

   micro avg       0.90      0.91      0.90      3342
   macro avg       0.90      0.91      0.90      3342
weighted avg       0.90      0.91      0.90      3342

{'eval_loss': 0.07477401942014694, 'eval_precision': 0.8960962723803934, 'eval_recall': 0.9135248354278875, 'eval_f1': 0.9047266261668395, 'eval_accuracy': 0.9826949559774694, 'eval_runtime': 24.0914, 'eval_samples_per_second': 69.859, 'eval_steps_per_second': 4.4, 'epoch': 0.89}
{'loss': 0.0414, 'learning_rate': 8.960375452979268e-06, 'epoch': 1.04}
              precision    recall  f1-score   support

       NSWER       0.88      0.92      0.90      1659
     UESTION       0.88      0.91      0.89      1683

   micro avg       0.88      0.91      0.90      3342
   macro avg       0.88      0.91      0.90      3342
weighted avg       0.88      0.91      0.90      3342

{'eval_loss': 0.07902548462152481, 'eval_precision': 0.8784912179671753, 'eval_recall': 0.9129263913824057, 'eval_f1': 0.895377842993397, 'eval_accuracy': 0.9827161015941152, 'eval_runtime': 24.1017, 'eval_samples_per_second': 69.829, 'eval_steps_per_second': 4.398, 'epoch': 1.04}
{'loss': 0.0342, 'learning_rate': 8.811857660547734e-06, 'epoch': 1.19}
              precision    recall  f1-score   support

       NSWER       0.85      0.90      0.88      1659
     UESTION       0.85      0.90      0.88      1683

   micro avg       0.85      0.90      0.88      3342
   macro avg       0.85      0.90      0.88      3342
weighted avg       0.85      0.90      0.88      3342

{'eval_loss': 0.08712638169527054, 'eval_precision': 0.8498312710911136, 'eval_recall': 0.9042489527229204, 'eval_f1': 0.8761959988402435, 'eval_accuracy': 0.9834535549746385, 'eval_runtime': 24.053, 'eval_samples_per_second': 69.971, 'eval_steps_per_second': 4.407, 'epoch': 1.19}
{'loss': 0.0361, 'learning_rate': 8.663339868116201e-06, 'epoch': 1.34}
              precision    recall  f1-score   support

       NSWER       0.88      0.92      0.90      1659
     UESTION       0.88      0.91      0.89      1683

   micro avg       0.88      0.91      0.90      3342
   macro avg       0.88      0.91      0.90      3342
weighted avg       0.88      0.91      0.90      3342

{'eval_loss': 0.09565969556570053, 'eval_precision': 0.8780207134637514, 'eval_recall': 0.9132256134051466, 'eval_f1': 0.8952772073921971, 'eval_accuracy': 0.9827346040086803, 'eval_runtime': 24.3648, 'eval_samples_per_second': 69.075, 'eval_steps_per_second': 4.351, 'epoch': 1.34}
{'train_runtime': 4104.8075, 'train_samples_per_second': 328.049, 'train_steps_per_second': 41.008, 'train_loss': 0.057661560397677954, 'epoch': 1.34}
              precision    recall  f1-score   support

       NSWER       0.83      0.89      0.86      5623
     UESTION       0.83      0.89      0.86      5693

   micro avg       0.83      0.89      0.86     11316
   macro avg       0.83      0.89      0.86     11316
weighted avg       0.83      0.89      0.86     11316

{'epoch': 1.34,
 'eval_accuracy': 0.9836861150538402,
 'eval_f1': 0.8616948573381172,
 'eval_loss': 0.05290845409035683,
 'eval_precision': 0.8339120370370371,
 'eval_recall': 0.8913927182750089,
 'eval_runtime': 81.9202,
 'eval_samples_per_second': 69.494,
 'eval_steps_per_second': 4.346}
Accuracy: 0.9836861150538402
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	1e-5	num_train_epochs	10	END 4744639: Thu 12 Oct 2023 12:12:35 PM EEST
