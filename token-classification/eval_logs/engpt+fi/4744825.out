START 4744825: Thu 12 Oct 2023 11:15:54 AM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl'], test='../../data/qa_token_classification/annotated/test_annotated_dataset.jsonl', dev='../../data/qa_token_classification/annotated/dev_annotated_dataset.jsonl', batch=8, epochs=10, lr=5e-05, save=None, dataset=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138082
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138082
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 50
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 68
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.1535, 'learning_rate': 4.927582411216036e-05, 'epoch': 0.14}
              precision    recall  f1-score   support

       NSWER       0.02      0.03      0.02        40
     UESTION       0.24      0.20      0.21        46

   micro avg       0.12      0.12      0.12        86
   macro avg       0.13      0.11      0.12        86
weighted avg       0.14      0.12      0.13        86

{'eval_loss': 0.9985455870628357, 'eval_precision': 0.125, 'eval_recall': 0.11627906976744186, 'eval_f1': 0.12048192771084337, 'eval_accuracy': 0.6107314603897748, 'eval_runtime': 1.6222, 'eval_samples_per_second': 30.823, 'eval_steps_per_second': 2.466, 'epoch': 0.14}
{'loss': 0.1018, 'learning_rate': 4.855164822432072e-05, 'epoch': 0.29}
              precision    recall  f1-score   support

       NSWER       0.01      0.07      0.01        40
     UESTION       0.00      0.00      0.00        46

   micro avg       0.00      0.03      0.01        86
   macro avg       0.00      0.04      0.01        86
weighted avg       0.00      0.03      0.01        86

{'eval_loss': 1.1105232238769531, 'eval_precision': 0.004431314623338257, 'eval_recall': 0.03488372093023256, 'eval_f1': 0.007863695937090433, 'eval_accuracy': 0.60528980005062, 'eval_runtime': 0.5589, 'eval_samples_per_second': 89.466, 'eval_steps_per_second': 7.157, 'epoch': 0.29}
{'loss': 0.1035, 'learning_rate': 4.7827472336481086e-05, 'epoch': 0.43}
              precision    recall  f1-score   support

       NSWER       0.00      0.00      0.00        40
     UESTION       0.00      0.00      0.00        46

   micro avg       0.00      0.00      0.00        86
   macro avg       0.00      0.00      0.00        86
weighted avg       0.00      0.00      0.00        86

{'eval_loss': 1.3621286153793335, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.41622374082510755, 'eval_runtime': 0.5194, 'eval_samples_per_second': 96.265, 'eval_steps_per_second': 7.701, 'epoch': 0.43}
{'loss': 0.094, 'learning_rate': 4.7103296448641445e-05, 'epoch': 0.58}
              precision    recall  f1-score   support

       NSWER       0.06      0.12      0.08        40
     UESTION       0.07      0.11      0.09        46

   micro avg       0.06      0.12      0.08        86
   macro avg       0.06      0.12      0.08        86
weighted avg       0.07      0.12      0.08        86

{'eval_loss': 0.7358330488204956, 'eval_precision': 0.0641025641025641, 'eval_recall': 0.11627906976744186, 'eval_f1': 0.08264462809917356, 'eval_accuracy': 0.6088332067830929, 'eval_runtime': 0.7365, 'eval_samples_per_second': 67.888, 'eval_steps_per_second': 5.431, 'epoch': 0.58}
{'loss': 0.0912, 'learning_rate': 4.637912056080181e-05, 'epoch': 0.72}
              precision    recall  f1-score   support

       NSWER       0.09      0.20      0.13        40
     UESTION       0.08      0.15      0.11        46

   micro avg       0.09      0.17      0.12        86
   macro avg       0.09      0.18      0.12        86
weighted avg       0.09      0.17      0.11        86

{'eval_loss': 0.6807763576507568, 'eval_precision': 0.08620689655172414, 'eval_recall': 0.1744186046511628, 'eval_f1': 0.11538461538461538, 'eval_accuracy': 0.7074158440901037, 'eval_runtime': 0.5544, 'eval_samples_per_second': 90.194, 'eval_steps_per_second': 7.216, 'epoch': 0.72}
{'loss': 0.083, 'learning_rate': 4.565494467296217e-05, 'epoch': 0.87}
              precision    recall  f1-score   support

       NSWER       0.02      0.05      0.03        40
     UESTION       0.04      0.02      0.03        46

   micro avg       0.03      0.03      0.03        86
   macro avg       0.03      0.04      0.03        86
weighted avg       0.03      0.03      0.03        86

{'eval_loss': 0.8636243939399719, 'eval_precision': 0.027777777777777776, 'eval_recall': 0.03488372093023256, 'eval_f1': 0.030927835051546396, 'eval_accuracy': 0.5435332827132372, 'eval_runtime': 1.55, 'eval_samples_per_second': 32.259, 'eval_steps_per_second': 2.581, 'epoch': 0.87}
{'loss': 0.0808, 'learning_rate': 4.4930768785122536e-05, 'epoch': 1.01}
              precision    recall  f1-score   support

       NSWER       0.04      0.05      0.04        40
     UESTION       0.04      0.07      0.05        46

   micro avg       0.04      0.06      0.04        86
   macro avg       0.04      0.06      0.04        86
weighted avg       0.04      0.06      0.04        86

{'eval_loss': 0.9082854390144348, 'eval_precision': 0.036231884057971016, 'eval_recall': 0.05813953488372093, 'eval_f1': 0.044642857142857144, 'eval_accuracy': 0.5960516324981018, 'eval_runtime': 0.5198, 'eval_samples_per_second': 96.187, 'eval_steps_per_second': 7.695, 'epoch': 1.01}
{'loss': 0.0673, 'learning_rate': 4.4206592897282895e-05, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.07      0.15      0.09        40
     UESTION       0.17      0.20      0.18        46

   micro avg       0.10      0.17      0.13        86
   macro avg       0.12      0.17      0.14        86
weighted avg       0.12      0.17      0.14        86

{'eval_loss': 0.6308512091636658, 'eval_precision': 0.1048951048951049, 'eval_recall': 0.1744186046511628, 'eval_f1': 0.1310043668122271, 'eval_accuracy': 0.7212098202986585, 'eval_runtime': 0.5392, 'eval_samples_per_second': 92.73, 'eval_steps_per_second': 7.418, 'epoch': 1.16}
{'loss': 0.0692, 'learning_rate': 4.3482417009443254e-05, 'epoch': 1.3}
              precision    recall  f1-score   support

       NSWER       0.00      0.00      0.00        40
     UESTION       0.09      0.09      0.09        46

   micro avg       0.05      0.05      0.05        86
   macro avg       0.04      0.04      0.04        86
weighted avg       0.05      0.05      0.05        86

{'eval_loss': 0.8274716734886169, 'eval_precision': 0.05128205128205128, 'eval_recall': 0.046511627906976744, 'eval_f1': 0.04878048780487805, 'eval_accuracy': 0.5377119716527461, 'eval_runtime': 1.5388, 'eval_samples_per_second': 32.492, 'eval_steps_per_second': 2.599, 'epoch': 1.3}
{'loss': 0.0682, 'learning_rate': 4.275824112160361e-05, 'epoch': 1.45}
              precision    recall  f1-score   support

       NSWER       0.05      0.07      0.06        40
     UESTION       0.06      0.11      0.08        46

   micro avg       0.06      0.09      0.07        86
   macro avg       0.06      0.09      0.07        86
weighted avg       0.06      0.09      0.07        86

{'eval_loss': 1.0229899883270264, 'eval_precision': 0.05673758865248227, 'eval_recall': 0.09302325581395349, 'eval_f1': 0.07048458149779735, 'eval_accuracy': 0.7146292077954948, 'eval_runtime': 0.5435, 'eval_samples_per_second': 92.003, 'eval_steps_per_second': 7.36, 'epoch': 1.45}
{'loss': 0.0673, 'learning_rate': 4.203406523376398e-05, 'epoch': 1.59}
              precision    recall  f1-score   support

       NSWER       0.05      0.03      0.03        40
     UESTION       0.07      0.07      0.07        46

   micro avg       0.06      0.05      0.05        86
   macro avg       0.06      0.05      0.05        86
weighted avg       0.06      0.05      0.05        86

{'eval_loss': 1.3116745948791504, 'eval_precision': 0.06451612903225806, 'eval_recall': 0.046511627906976744, 'eval_f1': 0.05405405405405405, 'eval_accuracy': 0.5813718046064288, 'eval_runtime': 0.5225, 'eval_samples_per_second': 95.698, 'eval_steps_per_second': 7.656, 'epoch': 1.59}
{'loss': 0.0696, 'learning_rate': 4.130988934592434e-05, 'epoch': 1.74}
              precision    recall  f1-score   support

       NSWER       0.00      0.00      0.00        40
     UESTION       0.00      0.00      0.00        46

   micro avg       0.00      0.00      0.00        86
   macro avg       0.00      0.00      0.00        86
weighted avg       0.00      0.00      0.00        86

{'eval_loss': 1.3950332403182983, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.4330549228043533, 'eval_runtime': 0.512, 'eval_samples_per_second': 97.665, 'eval_steps_per_second': 7.813, 'epoch': 1.74}
{'loss': 0.0711, 'learning_rate': 4.0585713458084704e-05, 'epoch': 1.88}
              precision    recall  f1-score   support

       NSWER       0.00      0.00      0.00        40
     UESTION       0.00      0.00      0.00        46

   micro avg       0.00      0.00      0.00        86
   macro avg       0.00      0.00      0.00        86
weighted avg       0.00      0.00      0.00        86

{'eval_loss': 1.0917143821716309, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.41445203745887116, 'eval_runtime': 0.5006, 'eval_samples_per_second': 99.887, 'eval_steps_per_second': 7.991, 'epoch': 1.88}
{'train_runtime': 6399.3258, 'train_samples_per_second': 215.776, 'train_steps_per_second': 26.973, 'train_loss': 0.08618951040414663, 'epoch': 1.88}
              precision    recall  f1-score   support

       NSWER       0.12      0.20      0.15        59
     UESTION       0.22      0.23      0.23        73

   micro avg       0.16      0.22      0.19       132
   macro avg       0.17      0.22      0.19       132
weighted avg       0.18      0.22      0.19       132

{'epoch': 1.88,
 'eval_accuracy': 0.7430941830866409,
 'eval_f1': 0.1864951768488746,
 'eval_loss': 0.6702442765235901,
 'eval_precision': 0.16201117318435754,
 'eval_recall': 0.2196969696969697,
 'eval_runtime': 0.7577,
 'eval_samples_per_second': 89.751,
 'eval_steps_per_second': 6.599}
Accuracy: 0.7430941830866409
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	5e-5	num_train_epochs	10	END 4744825: Thu 12 Oct 2023 01:07:59 PM EEST
