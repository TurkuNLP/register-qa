START 4753168: Fri 13 Oct 2023 12:18:34 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl'], test='../../data/qa_token_classification/annotated/en_test_dataset.jsonl', dev='../../data/qa_token_classification/annotated/en_dev_dataset.jsonl', batch=8, epochs=10, lr=2e-05, save=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138082
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138082
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 40
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 60
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.143, 'learning_rate': 1.9710329644864146e-05, 'epoch': 0.14}
              precision    recall  f1-score   support

       NSWER       0.02      0.07      0.04        40
     UESTION       0.02      0.02      0.02        92

   micro avg       0.02      0.04      0.03       132
   macro avg       0.02      0.05      0.03       132
weighted avg       0.02      0.04      0.02       132

{'eval_loss': 5.001722812652588, 'eval_precision': 0.02, 'eval_recall': 0.03787878787878788, 'eval_f1': 0.02617801047120419, 'eval_accuracy': 0.3386178861788618, 'eval_runtime': 0.6053, 'eval_samples_per_second': 66.081, 'eval_steps_per_second': 4.956, 'epoch': 0.14}
{'loss': 0.0848, 'learning_rate': 1.942065928972829e-05, 'epoch': 0.29}
              precision    recall  f1-score   support

       NSWER       0.03      0.12      0.05        40
     UESTION       0.02      0.03      0.03        92

   micro avg       0.03      0.06      0.04       132
   macro avg       0.03      0.08      0.04       132
weighted avg       0.02      0.06      0.03       132

{'eval_loss': 4.257176399230957, 'eval_precision': 0.027586206896551724, 'eval_recall': 0.06060606060606061, 'eval_f1': 0.037914691943127965, 'eval_accuracy': 0.37896341463414634, 'eval_runtime': 0.5796, 'eval_samples_per_second': 69.014, 'eval_steps_per_second': 5.176, 'epoch': 0.29}
{'loss': 0.0745, 'learning_rate': 1.9130988934592435e-05, 'epoch': 0.43}
              precision    recall  f1-score   support

       NSWER       0.06      0.15      0.08        40
     UESTION       0.03      0.04      0.04        92

   micro avg       0.04      0.08      0.06       132
   macro avg       0.05      0.10      0.06       132
weighted avg       0.04      0.08      0.05       132

{'eval_loss': 4.46737003326416, 'eval_precision': 0.04424778761061947, 'eval_recall': 0.07575757575757576, 'eval_f1': 0.0558659217877095, 'eval_accuracy': 0.3434959349593496, 'eval_runtime': 0.5761, 'eval_samples_per_second': 69.435, 'eval_steps_per_second': 5.208, 'epoch': 0.43}
{'loss': 0.0771, 'learning_rate': 1.884131857945658e-05, 'epoch': 0.58}
              precision    recall  f1-score   support

       NSWER       0.05      0.10      0.07        40
     UESTION       0.01      0.02      0.01        92

   micro avg       0.02      0.05      0.03       132
   macro avg       0.03      0.06      0.04       132
weighted avg       0.02      0.05      0.03       132

{'eval_loss': 4.090691566467285, 'eval_precision': 0.02390438247011952, 'eval_recall': 0.045454545454545456, 'eval_f1': 0.03133159268929504, 'eval_accuracy': 0.3306910569105691, 'eval_runtime': 0.5774, 'eval_samples_per_second': 69.272, 'eval_steps_per_second': 5.195, 'epoch': 0.58}
{'loss': 0.0636, 'learning_rate': 1.8551648224320723e-05, 'epoch': 0.72}
              precision    recall  f1-score   support

       NSWER       0.03      0.10      0.05        40
     UESTION       0.02      0.03      0.03        92

   micro avg       0.03      0.05      0.04       132
   macro avg       0.03      0.07      0.04       132
weighted avg       0.03      0.05      0.03       132

{'eval_loss': 4.939658164978027, 'eval_precision': 0.027450980392156862, 'eval_recall': 0.05303030303030303, 'eval_f1': 0.03617571059431525, 'eval_accuracy': 0.321239837398374, 'eval_runtime': 0.7254, 'eval_samples_per_second': 55.141, 'eval_steps_per_second': 4.136, 'epoch': 0.72}
{'loss': 0.062, 'learning_rate': 1.8261977869184867e-05, 'epoch': 0.87}
              precision    recall  f1-score   support

       NSWER       0.03      0.10      0.05        40
     UESTION       0.02      0.03      0.03        92

   micro avg       0.03      0.05      0.04       132
   macro avg       0.03      0.07      0.04       132
weighted avg       0.03      0.05      0.03       132

{'eval_loss': 4.501357555389404, 'eval_precision': 0.027237354085603113, 'eval_recall': 0.05303030303030303, 'eval_f1': 0.035989717223650394, 'eval_accuracy': 0.30914634146341463, 'eval_runtime': 0.57, 'eval_samples_per_second': 70.18, 'eval_steps_per_second': 5.263, 'epoch': 0.87}
{'loss': 0.0607, 'learning_rate': 1.7972307514049015e-05, 'epoch': 1.01}
              precision    recall  f1-score   support

       NSWER       0.04      0.07      0.05        40
     UESTION       0.03      0.03      0.03        92

   micro avg       0.04      0.05      0.04       132
   macro avg       0.04      0.05      0.04       132
weighted avg       0.04      0.05      0.04       132

{'eval_loss': 5.518787384033203, 'eval_precision': 0.03550295857988166, 'eval_recall': 0.045454545454545456, 'eval_f1': 0.03986710963455149, 'eval_accuracy': 0.31808943089430897, 'eval_runtime': 0.5728, 'eval_samples_per_second': 69.826, 'eval_steps_per_second': 5.237, 'epoch': 1.01}
{'loss': 0.0507, 'learning_rate': 1.768263715891316e-05, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.04      0.05      0.04        40
     UESTION       0.04      0.02      0.03        92

   micro avg       0.04      0.03      0.03       132
   macro avg       0.04      0.04      0.04       132
weighted avg       0.04      0.03      0.03       132

{'eval_loss': 6.027073860168457, 'eval_precision': 0.03669724770642202, 'eval_recall': 0.030303030303030304, 'eval_f1': 0.03319502074688797, 'eval_accuracy': 0.3279471544715447, 'eval_runtime': 0.5788, 'eval_samples_per_second': 69.111, 'eval_steps_per_second': 5.183, 'epoch': 1.16}
{'loss': 0.05, 'learning_rate': 1.7392966803777304e-05, 'epoch': 1.3}
              precision    recall  f1-score   support

       NSWER       0.06      0.12      0.08        40
     UESTION       0.03      0.03      0.03        92

   micro avg       0.04      0.06      0.05       132
   macro avg       0.04      0.08      0.05       132
weighted avg       0.04      0.06      0.05       132

{'eval_loss': 5.816729545593262, 'eval_precision': 0.043243243243243246, 'eval_recall': 0.06060606060606061, 'eval_f1': 0.050473186119873815, 'eval_accuracy': 0.32215447154471544, 'eval_runtime': 0.6002, 'eval_samples_per_second': 66.645, 'eval_steps_per_second': 4.998, 'epoch': 1.3}
{'train_runtime': 3974.589, 'train_samples_per_second': 347.412, 'train_steps_per_second': 43.428, 'train_loss': 0.07405242919921876, 'epoch': 1.3}
              precision    recall  f1-score   support

       NSWER       0.05      0.09      0.06        79
     UESTION       0.02      0.03      0.02       109

   micro avg       0.03      0.05      0.04       188
   macro avg       0.03      0.06      0.04       188
weighted avg       0.03      0.05      0.04       188

{'epoch': 1.3,
 'eval_accuracy': 0.28811651305143177,
 'eval_f1': 0.03787878787878788,
 'eval_loss': 4.30388879776001,
 'eval_precision': 0.029411764705882353,
 'eval_recall': 0.05319148936170213,
 'eval_runtime': 0.9167,
 'eval_samples_per_second': 65.449,
 'eval_steps_per_second': 4.363}
Accuracy: 0.28811651305143177
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	2e-5	num_train_epochs	10	END 4753168: Fri 13 Oct 2023 01:30:15 PM EEST
