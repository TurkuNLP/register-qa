START 4753294: Fri 13 Oct 2023 12:31:54 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/cleaned2_train_annotated_dataset.jsonl', '../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl'], test='../../data/qa_token_classification/annotated/en_test_dataset.jsonl', dev='../../data/qa_token_classification/annotated/en_dev_dataset.jsonl', batch=8, epochs=10, lr=1e-05, save=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
in dictionary: 2
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138182
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 138182
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 40
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 60
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.15, 'learning_rate': 9.855265443177214e-06, 'epoch': 0.14}
              precision    recall  f1-score   support

       NSWER       0.03      0.07      0.04        40
     UESTION       0.03      0.03      0.03        92

   micro avg       0.03      0.05      0.03       132
   macro avg       0.03      0.05      0.03       132
weighted avg       0.03      0.05      0.03       132

{'eval_loss': 4.19308614730835, 'eval_precision': 0.026905829596412557, 'eval_recall': 0.045454545454545456, 'eval_f1': 0.03380281690140845, 'eval_accuracy': 0.3261178861788618, 'eval_runtime': 0.5709, 'eval_samples_per_second': 70.068, 'eval_steps_per_second': 5.255, 'epoch': 0.14}
{'loss': 0.0821, 'learning_rate': 9.710530886354427e-06, 'epoch': 0.29}
              precision    recall  f1-score   support

       NSWER       0.01      0.05      0.02        40
     UESTION       0.03      0.04      0.03        92

   micro avg       0.02      0.05      0.03       132
   macro avg       0.02      0.05      0.03       132
weighted avg       0.02      0.05      0.03       132

{'eval_loss': 4.1691670417785645, 'eval_precision': 0.020338983050847456, 'eval_recall': 0.045454545454545456, 'eval_f1': 0.028103044496487116, 'eval_accuracy': 0.32916666666666666, 'eval_runtime': 0.5687, 'eval_samples_per_second': 70.341, 'eval_steps_per_second': 5.276, 'epoch': 0.29}
{'loss': 0.0745, 'learning_rate': 9.56579632953164e-06, 'epoch': 0.43}
              precision    recall  f1-score   support

       NSWER       0.04      0.10      0.05        40
     UESTION       0.04      0.04      0.04        92

   micro avg       0.04      0.06      0.05       132
   macro avg       0.04      0.07      0.05       132
weighted avg       0.04      0.06      0.04       132

{'eval_loss': 5.1481218338012695, 'eval_precision': 0.03636363636363636, 'eval_recall': 0.06060606060606061, 'eval_f1': 0.04545454545454545, 'eval_accuracy': 0.3559959349593496, 'eval_runtime': 0.5675, 'eval_samples_per_second': 70.49, 'eval_steps_per_second': 5.287, 'epoch': 0.43}
{'loss': 0.0697, 'learning_rate': 9.421061772708852e-06, 'epoch': 0.58}
              precision    recall  f1-score   support

       NSWER       0.08      0.17      0.11        40
     UESTION       0.08      0.08      0.08        92

   micro avg       0.08      0.11      0.09       132
   macro avg       0.08      0.13      0.09       132
weighted avg       0.08      0.11      0.09       132

{'eval_loss': 5.3288187980651855, 'eval_precision': 0.08092485549132948, 'eval_recall': 0.10606060606060606, 'eval_f1': 0.09180327868852459, 'eval_accuracy': 0.3842479674796748, 'eval_runtime': 0.6232, 'eval_samples_per_second': 64.183, 'eval_steps_per_second': 4.814, 'epoch': 0.58}
{'loss': 0.0686, 'learning_rate': 9.276327215886066e-06, 'epoch': 0.72}
              precision    recall  f1-score   support

       NSWER       0.04      0.12      0.06        40
     UESTION       0.05      0.07      0.06        92

   micro avg       0.04      0.08      0.06       132
   macro avg       0.04      0.10      0.06       132
weighted avg       0.05      0.08      0.06       132

{'eval_loss': 4.088601112365723, 'eval_precision': 0.043824701195219126, 'eval_recall': 0.08333333333333333, 'eval_f1': 0.057441253263707574, 'eval_accuracy': 0.370020325203252, 'eval_runtime': 0.5653, 'eval_samples_per_second': 70.757, 'eval_steps_per_second': 5.307, 'epoch': 0.72}
{'loss': 0.0611, 'learning_rate': 9.131592659063279e-06, 'epoch': 0.87}
              precision    recall  f1-score   support

       NSWER       0.08      0.23      0.12        40
     UESTION       0.05      0.07      0.06        92

   micro avg       0.06      0.11      0.08       132
   macro avg       0.07      0.15      0.09       132
weighted avg       0.06      0.11      0.08       132

{'eval_loss': 4.676438808441162, 'eval_precision': 0.06465517241379311, 'eval_recall': 0.11363636363636363, 'eval_f1': 0.08241758241758242, 'eval_accuracy': 0.3845528455284553, 'eval_runtime': 0.6, 'eval_samples_per_second': 66.669, 'eval_steps_per_second': 5.0, 'epoch': 0.87}
{'loss': 0.0591, 'learning_rate': 8.986858102240492e-06, 'epoch': 1.01}
              precision    recall  f1-score   support

       NSWER       0.05      0.12      0.08        40
     UESTION       0.07      0.08      0.07        92

   micro avg       0.06      0.09      0.08       132
   macro avg       0.06      0.10      0.08       132
weighted avg       0.07      0.09      0.08       132

{'eval_loss': 5.41811466217041, 'eval_precision': 0.06417112299465241, 'eval_recall': 0.09090909090909091, 'eval_f1': 0.07523510971786834, 'eval_accuracy': 0.35335365853658535, 'eval_runtime': 0.5833, 'eval_samples_per_second': 68.575, 'eval_steps_per_second': 5.143, 'epoch': 1.01}
{'loss': 0.0477, 'learning_rate': 8.842123545417704e-06, 'epoch': 1.16}
              precision    recall  f1-score   support

       NSWER       0.10      0.15      0.12        40
     UESTION       0.07      0.07      0.07        92

   micro avg       0.08      0.09      0.09       132
   macro avg       0.08      0.11      0.09       132
weighted avg       0.08      0.09      0.08       132

{'eval_loss': 5.421699523925781, 'eval_precision': 0.08163265306122448, 'eval_recall': 0.09090909090909091, 'eval_f1': 0.08602150537634408, 'eval_accuracy': 0.3771341463414634, 'eval_runtime': 0.6087, 'eval_samples_per_second': 65.717, 'eval_steps_per_second': 4.929, 'epoch': 1.16}
{'loss': 0.0464, 'learning_rate': 8.697388988594919e-06, 'epoch': 1.3}
              precision    recall  f1-score   support

       NSWER       0.08      0.15      0.11        40
     UESTION       0.06      0.05      0.06        92

   micro avg       0.07      0.08      0.08       132
   macro avg       0.07      0.10      0.08       132
weighted avg       0.07      0.08      0.07       132

{'eval_loss': 6.104981899261475, 'eval_precision': 0.07333333333333333, 'eval_recall': 0.08333333333333333, 'eval_f1': 0.07801418439716311, 'eval_accuracy': 0.36605691056910566, 'eval_runtime': 0.5674, 'eval_samples_per_second': 70.498, 'eval_steps_per_second': 5.287, 'epoch': 1.3}
{'loss': 0.0477, 'learning_rate': 8.55265443177213e-06, 'epoch': 1.45}
              precision    recall  f1-score   support

       NSWER       0.08      0.23      0.12        40
     UESTION       0.05      0.07      0.05        92

   micro avg       0.06      0.11      0.08       132
   macro avg       0.06      0.15      0.08       132
weighted avg       0.06      0.11      0.07       132

{'eval_loss': 5.439000129699707, 'eval_precision': 0.06048387096774194, 'eval_recall': 0.11363636363636363, 'eval_f1': 0.07894736842105263, 'eval_accuracy': 0.31097560975609756, 'eval_runtime': 0.6054, 'eval_samples_per_second': 66.072, 'eval_steps_per_second': 4.955, 'epoch': 1.45}
{'train_runtime': 4337.2337, 'train_samples_per_second': 318.595, 'train_steps_per_second': 39.825, 'train_loss': 0.07069571563720703, 'epoch': 1.45}
              precision    recall  f1-score   support

       NSWER       0.03      0.09      0.05        79
     UESTION       0.02      0.04      0.02       109

   micro avg       0.02      0.06      0.03       188
   macro avg       0.03      0.06      0.04       188
weighted avg       0.02      0.06      0.03       188

{'epoch': 1.45,
 'eval_accuracy': 0.3206923239287976,
 'eval_f1': 0.03486529318541997,
 'eval_loss': 4.834855079650879,
 'eval_precision': 0.024830699774266364,
 'eval_recall': 0.05851063829787234,
 'eval_runtime': 0.8795,
 'eval_samples_per_second': 68.217,
 'eval_steps_per_second': 4.548}
Accuracy: 0.3206923239287976
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	1e-5	num_train_epochs	10	END 4753294: Fri 13 Oct 2023 01:50:55 PM EEST
