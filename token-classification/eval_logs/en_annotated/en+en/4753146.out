START 4753146: Fri 13 Oct 2023 12:18:34 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2'], test='../../data/qa_token_classification/annotated/en_test_dataset.jsonl', dev='../../data/qa_token_classification/annotated/en_dev_dataset.jsonl', batch=8, epochs=10, lr=5e-05, save=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 40
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 60
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.1285, 'learning_rate': 4.925741103784234e-05, 'epoch': 0.15}
              precision    recall  f1-score   support

       NSWER       0.01      0.03      0.02        40
     UESTION       0.01      0.01      0.01        92

   micro avg       0.01      0.02      0.01       132
   macro avg       0.01      0.02      0.01       132
weighted avg       0.01      0.02      0.01       132

{'eval_loss': 7.4780426025390625, 'eval_precision': 0.011049723756906077, 'eval_recall': 0.015151515151515152, 'eval_f1': 0.012779552715654952, 'eval_accuracy': 0.2893292682926829, 'eval_runtime': 0.6051, 'eval_samples_per_second': 66.108, 'eval_steps_per_second': 4.958, 'epoch': 0.15}
{'loss': 0.0889, 'learning_rate': 4.851482207568467e-05, 'epoch': 0.3}
              precision    recall  f1-score   support

       NSWER       0.01      0.03      0.01        40
     UESTION       0.02      0.02      0.02        92

   micro avg       0.02      0.02      0.02       132
   macro avg       0.02      0.02      0.02       132
weighted avg       0.02      0.02      0.02       132

{'eval_loss': 8.445657730102539, 'eval_precision': 0.015873015873015872, 'eval_recall': 0.022727272727272728, 'eval_f1': 0.018691588785046728, 'eval_accuracy': 0.338719512195122, 'eval_runtime': 0.5737, 'eval_samples_per_second': 69.721, 'eval_steps_per_second': 5.229, 'epoch': 0.3}
{'loss': 0.077, 'learning_rate': 4.7772233113527006e-05, 'epoch': 0.45}
              precision    recall  f1-score   support

       NSWER       0.07      0.10      0.08        40
     UESTION       0.03      0.02      0.03        92

   micro avg       0.05      0.05      0.05       132
   macro avg       0.05      0.06      0.05       132
weighted avg       0.04      0.05      0.04       132

{'eval_loss': 9.445745468139648, 'eval_precision': 0.049586776859504134, 'eval_recall': 0.045454545454545456, 'eval_f1': 0.047430830039525695, 'eval_accuracy': 0.31382113821138213, 'eval_runtime': 0.5638, 'eval_samples_per_second': 70.951, 'eval_steps_per_second': 5.321, 'epoch': 0.45}
{'loss': 0.0712, 'learning_rate': 4.7029644151369336e-05, 'epoch': 0.59}
              precision    recall  f1-score   support

       NSWER       0.04      0.07      0.05        40
     UESTION       0.03      0.02      0.02        92

   micro avg       0.03      0.04      0.04       132
   macro avg       0.03      0.05      0.04       132
weighted avg       0.03      0.04      0.03       132

{'eval_loss': 9.78898811340332, 'eval_precision': 0.03289473684210526, 'eval_recall': 0.03787878787878788, 'eval_f1': 0.035211267605633804, 'eval_accuracy': 0.308130081300813, 'eval_runtime': 0.5739, 'eval_samples_per_second': 69.699, 'eval_steps_per_second': 5.227, 'epoch': 0.59}
{'loss': 0.0652, 'learning_rate': 4.628705518921167e-05, 'epoch': 0.74}
              precision    recall  f1-score   support

       NSWER       0.06      0.10      0.07        40
     UESTION       0.04      0.03      0.04        92

   micro avg       0.05      0.05      0.05       132
   macro avg       0.05      0.07      0.06       132
weighted avg       0.05      0.05      0.05       132

{'eval_loss': 11.017664909362793, 'eval_precision': 0.04929577464788732, 'eval_recall': 0.05303030303030303, 'eval_f1': 0.051094890510948905, 'eval_accuracy': 0.2920731707317073, 'eval_runtime': 0.5825, 'eval_samples_per_second': 68.675, 'eval_steps_per_second': 5.151, 'epoch': 0.74}
{'loss': 0.0652, 'learning_rate': 4.5544466227054e-05, 'epoch': 0.89}
              precision    recall  f1-score   support

       NSWER       0.04      0.07      0.05        40
     UESTION       0.04      0.03      0.04        92

   micro avg       0.04      0.05      0.04       132
   macro avg       0.04      0.05      0.04       132
weighted avg       0.04      0.05      0.04       132

{'eval_loss': 12.051847457885742, 'eval_precision': 0.04081632653061224, 'eval_recall': 0.045454545454545456, 'eval_f1': 0.04301075268817204, 'eval_accuracy': 0.2761178861788618, 'eval_runtime': 0.5754, 'eval_samples_per_second': 69.515, 'eval_steps_per_second': 5.214, 'epoch': 0.89}
{'train_runtime': 2566.3613, 'train_samples_per_second': 524.704, 'train_steps_per_second': 65.591, 'train_loss': 0.0826540283203125, 'epoch': 0.89}
              precision    recall  f1-score   support

       NSWER       0.06      0.10      0.07        79
     UESTION       0.03      0.05      0.04       109

   micro avg       0.05      0.07      0.05       188
   macro avg       0.05      0.07      0.06       188
weighted avg       0.04      0.07      0.05       188

{'epoch': 0.89,
 'eval_accuracy': 0.29817772461830716,
 'eval_f1': 0.054621848739495805,
 'eval_loss': 7.371084690093994,
 'eval_precision': 0.04513888888888889,
 'eval_recall': 0.06914893617021277,
 'eval_runtime': 0.8266,
 'eval_samples_per_second': 72.583,
 'eval_steps_per_second': 4.839}
Accuracy: 0.29817772461830716
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	5e-5	num_train_epochs	10	END 4753146: Fri 13 Oct 2023 01:06:36 PM EEST
