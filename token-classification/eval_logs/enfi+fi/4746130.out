START 4746130: Thu 12 Oct 2023 01:17:47 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/train_annotated_dataset.jsonl'], test='../../data/qa_token_classification/annotated/test_annotated_dataset.jsonl', dev='../../data/qa_token_classification//annotated/dev_annotated_dataset.jsonl', batch=8, epochs=10, lr=3e-05, save=None, dataset=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 134758
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 134758
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 50
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 68
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.2706, 'learning_rate': 2.9955476402493325e-05, 'epoch': 0.01}
              precision    recall  f1-score   support

       NSWER       0.02      0.05      0.03        40
     UESTION       0.01      0.02      0.01        46

   micro avg       0.01      0.03      0.02        86
   macro avg       0.01      0.04      0.02        86
weighted avg       0.01      0.03      0.02        86

{'eval_loss': 3.5493712425231934, 'eval_precision': 0.01485148514851485, 'eval_recall': 0.03488372093023256, 'eval_f1': 0.02083333333333333, 'eval_accuracy': 0.4695013920526449, 'eval_runtime': 1.1044, 'eval_samples_per_second': 45.275, 'eval_steps_per_second': 3.622, 'epoch': 0.01}
{'loss': 0.147, 'learning_rate': 2.9910952804986643e-05, 'epoch': 0.03}
              precision    recall  f1-score   support

       NSWER       0.06      0.15      0.09        40
     UESTION       0.02      0.04      0.03        46

   micro avg       0.04      0.09      0.05        86
   macro avg       0.04      0.10      0.06        86
weighted avg       0.04      0.09      0.05        86

{'eval_loss': 3.4005844593048096, 'eval_precision': 0.03864734299516908, 'eval_recall': 0.09302325581395349, 'eval_f1': 0.0546075085324232, 'eval_accuracy': 0.48696532523411795, 'eval_runtime': 0.5639, 'eval_samples_per_second': 88.672, 'eval_steps_per_second': 7.094, 'epoch': 0.03}
{'loss': 0.1279, 'learning_rate': 2.9866429207479967e-05, 'epoch': 0.04}
              precision    recall  f1-score   support

       NSWER       0.05      0.15      0.08        40
     UESTION       0.02      0.04      0.02        46

   micro avg       0.03      0.09      0.05        86
   macro avg       0.04      0.10      0.05        86
weighted avg       0.03      0.09      0.05        86

{'eval_loss': 4.106768608093262, 'eval_precision': 0.034782608695652174, 'eval_recall': 0.09302325581395349, 'eval_f1': 0.05063291139240507, 'eval_accuracy': 0.4970893444697545, 'eval_runtime': 0.8872, 'eval_samples_per_second': 56.359, 'eval_steps_per_second': 4.509, 'epoch': 0.04}
{'loss': 0.0988, 'learning_rate': 2.9821905609973284e-05, 'epoch': 0.06}
              precision    recall  f1-score   support

       NSWER       0.06      0.15      0.09        40
     UESTION       0.03      0.07      0.04        46

   micro avg       0.04      0.10      0.06        86
   macro avg       0.04      0.11      0.06        86
weighted avg       0.04      0.10      0.06        86

{'eval_loss': 4.485897064208984, 'eval_precision': 0.04390243902439024, 'eval_recall': 0.10465116279069768, 'eval_f1': 0.06185567010309278, 'eval_accuracy': 0.4859529233105543, 'eval_runtime': 0.5757, 'eval_samples_per_second': 86.85, 'eval_steps_per_second': 6.948, 'epoch': 0.06}
{'loss': 0.1029, 'learning_rate': 2.977738201246661e-05, 'epoch': 0.07}
              precision    recall  f1-score   support

       NSWER       0.05      0.12      0.07        40
     UESTION       0.02      0.04      0.03        46

   micro avg       0.03      0.08      0.05        86
   macro avg       0.03      0.08      0.05        86
weighted avg       0.03      0.08      0.05        86

{'eval_loss': 4.469595909118652, 'eval_precision': 0.03286384976525822, 'eval_recall': 0.08139534883720931, 'eval_f1': 0.04682274247491639, 'eval_accuracy': 0.48911667932169073, 'eval_runtime': 0.5581, 'eval_samples_per_second': 89.596, 'eval_steps_per_second': 7.168, 'epoch': 0.07}
{'loss': 0.0912, 'learning_rate': 2.973285841495993e-05, 'epoch': 0.09}
              precision    recall  f1-score   support

       NSWER       0.08      0.17      0.11        40
     UESTION       0.02      0.04      0.03        46

   micro avg       0.05      0.10      0.07        86
   macro avg       0.05      0.11      0.07        86
weighted avg       0.05      0.10      0.07        86

{'eval_loss': 4.233808517456055, 'eval_precision': 0.05202312138728324, 'eval_recall': 0.10465116279069768, 'eval_f1': 0.0694980694980695, 'eval_accuracy': 0.46810933940774485, 'eval_runtime': 0.5559, 'eval_samples_per_second': 89.948, 'eval_steps_per_second': 7.196, 'epoch': 0.09}
{'loss': 0.1064, 'learning_rate': 2.968833481745325e-05, 'epoch': 0.1}
              precision    recall  f1-score   support

       NSWER       0.10      0.20      0.14        40
     UESTION       0.00      0.00      0.00        46

   micro avg       0.05      0.09      0.07        86
   macro avg       0.05      0.10      0.07        86
weighted avg       0.05      0.09      0.06        86

{'eval_loss': 3.8763086795806885, 'eval_precision': 0.05128205128205128, 'eval_recall': 0.09302325581395349, 'eval_f1': 0.06611570247933884, 'eval_accuracy': 0.4838015692229815, 'eval_runtime': 0.537, 'eval_samples_per_second': 93.103, 'eval_steps_per_second': 7.448, 'epoch': 0.1}
{'train_runtime': 358.992, 'train_samples_per_second': 3753.789, 'train_steps_per_second': 469.231, 'train_loss': 0.13496783229282924, 'epoch': 0.1}
              precision    recall  f1-score   support

       NSWER       0.03      0.08      0.05        59
     UESTION       0.02      0.04      0.03        73

   micro avg       0.03      0.06      0.04       132
   macro avg       0.03      0.06      0.04       132
weighted avg       0.02      0.06      0.03       132

{'epoch': 0.1,
 'eval_accuracy': 0.4899594607334779,
 'eval_f1': 0.03539823008849558,
 'eval_loss': 3.2994773387908936,
 'eval_precision': 0.025,
 'eval_recall': 0.06060606060606061,
 'eval_runtime': 0.757,
 'eval_samples_per_second': 89.825,
 'eval_steps_per_second': 6.605}
Accuracy: 0.4899594607334779
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	3e-5	num_train_epochs	10	END 4746130: Thu 12 Oct 2023 01:28:37 PM EEST
