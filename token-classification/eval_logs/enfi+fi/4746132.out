START 4746132: Thu 12 Oct 2023 01:17:54 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/dataset_punct2', '../../data/qa_token_classification/annotated/train_annotated_dataset.jsonl'], test='../../data/qa_token_classification/annotated/test_annotated_dataset.jsonl', dev='../../data/qa_token_classification//annotated/dev_annotated_dataset.jsonl', batch=8, epochs=10, lr=2e-05, save=None, dataset=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 134658
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 134758
    })
})
DatasetDict({
    train: Dataset({
        features: ['id', 'tags', 'tokens', 'text'],
        num_rows: 134758
    })
    validation: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 50
    })
    test: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 68
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.3157, 'learning_rate': 1.9970317601662218e-05, 'epoch': 0.01}
              precision    recall  f1-score   support

       NSWER       0.03      0.07      0.04        40
     UESTION       0.01      0.02      0.01        46

   micro avg       0.02      0.05      0.03        86
   macro avg       0.02      0.05      0.03        86
weighted avg       0.02      0.05      0.02        86

{'eval_loss': 3.662609577178955, 'eval_precision': 0.017467248908296942, 'eval_recall': 0.046511627906976744, 'eval_f1': 0.025396825396825393, 'eval_accuracy': 0.4791192103264996, 'eval_runtime': 0.5978, 'eval_samples_per_second': 83.636, 'eval_steps_per_second': 6.691, 'epoch': 0.01}
{'loss': 0.1541, 'learning_rate': 1.994063520332443e-05, 'epoch': 0.03}
              precision    recall  f1-score   support

       NSWER       0.07      0.17      0.10        40
     UESTION       0.02      0.04      0.03        46

   micro avg       0.04      0.10      0.06        86
   macro avg       0.04      0.11      0.06        86
weighted avg       0.04      0.10      0.06        86

{'eval_loss': 3.665889263153076, 'eval_precision': 0.04411764705882353, 'eval_recall': 0.10465116279069768, 'eval_f1': 0.06206896551724139, 'eval_accuracy': 0.4459630473297899, 'eval_runtime': 0.5594, 'eval_samples_per_second': 89.387, 'eval_steps_per_second': 7.151, 'epoch': 0.03}
{'loss': 0.1315, 'learning_rate': 1.9910952804986647e-05, 'epoch': 0.04}
              precision    recall  f1-score   support

       NSWER       0.05      0.12      0.07        40
     UESTION       0.02      0.04      0.03        46

   micro avg       0.03      0.08      0.05        86
   macro avg       0.03      0.08      0.05        86
weighted avg       0.03      0.08      0.05        86

{'eval_loss': 3.677639961242676, 'eval_precision': 0.03317535545023697, 'eval_recall': 0.08139534883720931, 'eval_f1': 0.04713804713804714, 'eval_accuracy': 0.5010124019235637, 'eval_runtime': 0.5588, 'eval_samples_per_second': 89.472, 'eval_steps_per_second': 7.158, 'epoch': 0.04}
{'loss': 0.1111, 'learning_rate': 1.988127040664886e-05, 'epoch': 0.06}
              precision    recall  f1-score   support

       NSWER       0.05      0.12      0.07        40
     UESTION       0.02      0.04      0.03        46

   micro avg       0.04      0.08      0.05        86
   macro avg       0.04      0.08      0.05        86
weighted avg       0.04      0.08      0.05        86

{'eval_loss': 3.3768415451049805, 'eval_precision': 0.03664921465968586, 'eval_recall': 0.08139534883720931, 'eval_f1': 0.05054151624548737, 'eval_accuracy': 0.4949379903821817, 'eval_runtime': 0.5573, 'eval_samples_per_second': 89.72, 'eval_steps_per_second': 7.178, 'epoch': 0.06}
{'loss': 0.1086, 'learning_rate': 1.9851588008311072e-05, 'epoch': 0.07}
              precision    recall  f1-score   support

       NSWER       0.07      0.20      0.11        40
     UESTION       0.01      0.02      0.01        46

   micro avg       0.04      0.10      0.06        86
   macro avg       0.04      0.11      0.06        86
weighted avg       0.04      0.10      0.06        86

{'eval_loss': 3.744297742843628, 'eval_precision': 0.0410958904109589, 'eval_recall': 0.10465116279069768, 'eval_f1': 0.059016393442622946, 'eval_accuracy': 0.4949379903821817, 'eval_runtime': 0.6216, 'eval_samples_per_second': 80.431, 'eval_steps_per_second': 6.435, 'epoch': 0.07}
{'loss': 0.1139, 'learning_rate': 1.9821905609973285e-05, 'epoch': 0.09}
              precision    recall  f1-score   support

       NSWER       0.06      0.20      0.09        40
     UESTION       0.02      0.04      0.02        46

   micro avg       0.04      0.12      0.06        86
   macro avg       0.04      0.12      0.06        86
weighted avg       0.04      0.12      0.06        86

{'eval_loss': 3.896987199783325, 'eval_precision': 0.038461538461538464, 'eval_recall': 0.11627906976744186, 'eval_f1': 0.05780346820809248, 'eval_accuracy': 0.4845608706656543, 'eval_runtime': 0.5893, 'eval_samples_per_second': 84.853, 'eval_steps_per_second': 6.788, 'epoch': 0.09}
{'loss': 0.083, 'learning_rate': 1.97922232116355e-05, 'epoch': 0.1}
              precision    recall  f1-score   support

       NSWER       0.07      0.17      0.10        40
     UESTION       0.03      0.07      0.04        46

   micro avg       0.05      0.12      0.07        86
   macro avg       0.05      0.12      0.07        86
weighted avg       0.05      0.12      0.07        86

{'eval_loss': 4.203692436218262, 'eval_precision': 0.05291005291005291, 'eval_recall': 0.11627906976744186, 'eval_f1': 0.07272727272727272, 'eval_accuracy': 0.5060744115413819, 'eval_runtime': 0.5303, 'eval_samples_per_second': 94.284, 'eval_steps_per_second': 7.543, 'epoch': 0.1}
{'loss': 0.1137, 'learning_rate': 1.9762540813297717e-05, 'epoch': 0.12}
              precision    recall  f1-score   support

       NSWER       0.06      0.17      0.09        40
     UESTION       0.02      0.04      0.02        46

   micro avg       0.04      0.10      0.06        86
   macro avg       0.04      0.11      0.06        86
weighted avg       0.04      0.10      0.05        86

{'eval_loss': 3.712597608566284, 'eval_precision': 0.03829787234042553, 'eval_recall': 0.10465116279069768, 'eval_f1': 0.056074766355140186, 'eval_accuracy': 0.5206276891926095, 'eval_runtime': 0.5314, 'eval_samples_per_second': 94.086, 'eval_steps_per_second': 7.527, 'epoch': 0.12}
{'loss': 0.073, 'learning_rate': 1.973285841495993e-05, 'epoch': 0.13}
              precision    recall  f1-score   support

       NSWER       0.07      0.17      0.10        40
     UESTION       0.03      0.07      0.04        46

   micro avg       0.05      0.12      0.07        86
   macro avg       0.05      0.12      0.07        86
weighted avg       0.05      0.12      0.07        86

{'eval_loss': 3.9799306392669678, 'eval_precision': 0.04926108374384237, 'eval_recall': 0.11627906976744186, 'eval_f1': 0.06920415224913494, 'eval_accuracy': 0.5236648949633004, 'eval_runtime': 0.5297, 'eval_samples_per_second': 94.389, 'eval_steps_per_second': 7.551, 'epoch': 0.13}
{'train_runtime': 497.2678, 'train_samples_per_second': 2709.968, 'train_steps_per_second': 338.751, 'train_loss': 0.13383987850613063, 'epoch': 0.13}
              precision    recall  f1-score   support

       NSWER       0.05      0.17      0.08        59
     UESTION       0.04      0.10      0.06        73

   micro avg       0.05      0.13      0.07       132
   macro avg       0.05      0.13      0.07       132
weighted avg       0.05      0.13      0.07       132

{'epoch': 0.13,
 'eval_accuracy': 0.498538700857924,
 'eval_f1': 0.06841046277665996,
 'eval_loss': 3.2934722900390625,
 'eval_precision': 0.04657534246575343,
 'eval_recall': 0.12878787878787878,
 'eval_runtime': 0.7632,
 'eval_samples_per_second': 89.099,
 'eval_steps_per_second': 6.551}
Accuracy: 0.498538700857924
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	2e-5	num_train_epochs	10	END 4746132: Thu 12 Oct 2023 01:30:55 PM EEST
