START 4745170: Thu 12 Oct 2023 12:00:33 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl', '../../data/qa_token_classification/annotated/train_annotated_dataset.jsonl'], test='../../data/qa_token_classification/dataset_punct2', dev='../../data/qa_token_classification/dataset_punct2', batch=8, epochs=10, lr=5e-05, save=None, dataset=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3524
    })
})
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3524
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.8297, 'learning_rate': 4.71655328798186e-05, 'epoch': 0.57}
              precision    recall  f1-score   support

       NSWER       0.08      0.27      0.13      1659
     UESTION       0.13      0.34      0.19      1683

   micro avg       0.11      0.31      0.16      3342
   macro avg       0.11      0.31      0.16      3342
weighted avg       0.11      0.31      0.16      3342

{'eval_loss': 0.7585734128952026, 'eval_precision': 0.10519293924466339, 'eval_recall': 0.3067025733093956, 'eval_f1': 0.1566559682103011, 'eval_accuracy': 0.7835270359924827, 'eval_runtime': 24.521, 'eval_samples_per_second': 68.635, 'eval_steps_per_second': 4.323, 'epoch': 0.57}
{'loss': 0.7184, 'learning_rate': 4.433106575963719e-05, 'epoch': 1.13}
              precision    recall  f1-score   support

       NSWER       0.11      0.31      0.17      1659
     UESTION       0.11      0.30      0.16      1683

   micro avg       0.11      0.31      0.16      3342
   macro avg       0.11      0.31      0.16      3342
weighted avg       0.11      0.31      0.16      3342

{'eval_loss': 0.5835028886795044, 'eval_precision': 0.10870027653690705, 'eval_recall': 0.30580490724117293, 'eval_f1': 0.1603892027620841, 'eval_accuracy': 0.8337558051325697, 'eval_runtime': 25.0695, 'eval_samples_per_second': 67.134, 'eval_steps_per_second': 4.228, 'epoch': 1.13}
{'loss': 0.6209, 'learning_rate': 4.149659863945579e-05, 'epoch': 1.7}
              precision    recall  f1-score   support

       NSWER       0.13      0.34      0.19      1659
     UESTION       0.13      0.34      0.19      1683

   micro avg       0.13      0.34      0.19      3342
   macro avg       0.13      0.34      0.19      3342
weighted avg       0.13      0.34      0.19      3342

{'eval_loss': 0.5508585572242737, 'eval_precision': 0.13180183315929922, 'eval_recall': 0.3399162178336326, 'eval_f1': 0.18995067302065044, 'eval_accuracy': 0.8465039687679242, 'eval_runtime': 24.8349, 'eval_samples_per_second': 67.768, 'eval_steps_per_second': 4.268, 'epoch': 1.7}
{'loss': 0.572, 'learning_rate': 3.8662131519274384e-05, 'epoch': 2.27}
              precision    recall  f1-score   support

       NSWER       0.11      0.30      0.16      1659
     UESTION       0.15      0.31      0.20      1683

   micro avg       0.13      0.31      0.18      3342
   macro avg       0.13      0.31      0.18      3342
weighted avg       0.13      0.31      0.18      3342

{'eval_loss': 0.8846150636672974, 'eval_precision': 0.12756378189094547, 'eval_recall': 0.3052064631956912, 'eval_f1': 0.17992591285941084, 'eval_accuracy': 0.7250091851272306, 'eval_runtime': 24.2393, 'eval_samples_per_second': 69.433, 'eval_steps_per_second': 4.373, 'epoch': 2.27}
{'loss': 0.5041, 'learning_rate': 3.5827664399092974e-05, 'epoch': 2.83}
              precision    recall  f1-score   support

       NSWER       0.10      0.23      0.14      1659
     UESTION       0.13      0.30      0.18      1683

   micro avg       0.12      0.27      0.16      3342
   macro avg       0.12      0.27      0.16      3342
weighted avg       0.12      0.27      0.16      3342

{'eval_loss': 0.8050851225852966, 'eval_precision': 0.11555842479018721, 'eval_recall': 0.267803710353082, 'eval_f1': 0.16145034725354016, 'eval_accuracy': 0.7608615781502344, 'eval_runtime': 24.6822, 'eval_samples_per_second': 68.187, 'eval_steps_per_second': 4.295, 'epoch': 2.83}
{'loss': 0.4316, 'learning_rate': 3.2993197278911564e-05, 'epoch': 3.4}
              precision    recall  f1-score   support

       NSWER       0.11      0.25      0.15      1659
     UESTION       0.14      0.32      0.19      1683

   micro avg       0.12      0.28      0.17      3342
   macro avg       0.12      0.28      0.17      3342
weighted avg       0.12      0.28      0.17      3342

{'eval_loss': 0.8433930277824402, 'eval_precision': 0.12418386001566989, 'eval_recall': 0.2845601436265709, 'eval_f1': 0.1729090909090909, 'eval_accuracy': 0.7904786574647992, 'eval_runtime': 24.8741, 'eval_samples_per_second': 67.661, 'eval_steps_per_second': 4.261, 'epoch': 3.4}
{'loss': 0.3993, 'learning_rate': 3.0158730158730158e-05, 'epoch': 3.97}
              precision    recall  f1-score   support

       NSWER       0.11      0.30      0.16      1659
     UESTION       0.15      0.35      0.21      1683

   micro avg       0.13      0.32      0.18      3342
   macro avg       0.13      0.32      0.19      3342
weighted avg       0.13      0.32      0.19      3342

{'eval_loss': 0.7746796607971191, 'eval_precision': 0.1286004541651727, 'eval_recall': 0.32196289646918014, 'eval_f1': 0.18379024681868653, 'eval_accuracy': 0.7696687274832222, 'eval_runtime': 24.8147, 'eval_samples_per_second': 67.823, 'eval_steps_per_second': 4.272, 'epoch': 3.97}
{'loss': 0.303, 'learning_rate': 2.732426303854875e-05, 'epoch': 4.54}
              precision    recall  f1-score   support

       NSWER       0.15      0.34      0.21      1659
     UESTION       0.14      0.33      0.20      1683

   micro avg       0.14      0.34      0.20      3342
   macro avg       0.14      0.34      0.20      3342
weighted avg       0.14      0.34      0.20      3342

{'eval_loss': 0.7876548767089844, 'eval_precision': 0.1448346577800564, 'eval_recall': 0.3381208856971873, 'eval_f1': 0.2027997128499641, 'eval_accuracy': 0.8097185254104232, 'eval_runtime': 25.0001, 'eval_samples_per_second': 67.32, 'eval_steps_per_second': 4.24, 'epoch': 4.54}
{'train_runtime': 573.7115, 'train_samples_per_second': 61.425, 'train_steps_per_second': 7.687, 'train_loss': 0.5473916244506836, 'epoch': 4.54}
              precision    recall  f1-score   support

       NSWER       0.15      0.37      0.21      5623
     UESTION       0.14      0.35      0.20      5693

   micro avg       0.15      0.36      0.21     11316
   macro avg       0.15      0.36      0.21     11316
weighted avg       0.15      0.36      0.21     11316

{'epoch': 4.54,
 'eval_accuracy': 0.8568234205157585,
 'eval_f1': 0.20754428053698126,
 'eval_loss': 0.5134329795837402,
 'eval_precision': 0.1459125816407091,
 'eval_recall': 0.3593142453163662,
 'eval_runtime': 83.6638,
 'eval_samples_per_second': 68.046,
 'eval_steps_per_second': 4.255}
Accuracy: 0.8568234205157585
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	5e-5	num_train_epochs	10	END 4745170: Thu 12 Oct 2023 12:12:24 PM EEST
