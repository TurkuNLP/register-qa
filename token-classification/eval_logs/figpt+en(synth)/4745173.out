START 4745173: Thu 12 Oct 2023 12:00:44 PM EEST
Namespace(model_name='xlm-roberta-base', train=['../../data/qa_token_classification/annotated/cleaned2_chatgpt_annotations_dataset.jsonl', '../../data/qa_token_classification/annotated/train_annotated_dataset.jsonl'], test='../../data/qa_token_classification/dataset_punct2', dev='../../data/qa_token_classification/dataset_punct2', batch=8, epochs=10, lr=2e-05, save=None, dataset=None)
in dictionary: 0
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3424
    })
})
in dictionary: 1
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 100
    })
})
final train:
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3524
    })
})
DatasetDict({
    train: Dataset({
        features: ['tags', 'tokens', 'id', 'text'],
        num_rows: 3524
    })
    validation: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 1683
    })
    test: Dataset({
        features: ['id', 'tags', 'tokens'],
        num_rows: 5693
    })
})
['QUESTION', 'ANSWER', 'O']
3
tokenization
training
{'loss': 0.8155, 'learning_rate': 1.886621315192744e-05, 'epoch': 0.57}
              precision    recall  f1-score   support

       NSWER       0.02      0.13      0.04      1659
     UESTION       0.09      0.29      0.14      1683

   micro avg       0.05      0.21      0.08      3342
   macro avg       0.06      0.21      0.09      3342
weighted avg       0.06      0.21      0.09      3342

{'eval_loss': 0.9016813039779663, 'eval_precision': 0.04609466684052679, 'eval_recall': 0.21154997007779772, 'eval_f1': 0.07569593147751605, 'eval_accuracy': 0.6064483557961456, 'eval_runtime': 22.5593, 'eval_samples_per_second': 74.603, 'eval_steps_per_second': 4.699, 'epoch': 0.57}
{'loss': 0.6882, 'learning_rate': 1.7732426303854877e-05, 'epoch': 1.13}
              precision    recall  f1-score   support

       NSWER       0.02      0.10      0.03      1659
     UESTION       0.05      0.17      0.07      1683

   micro avg       0.03      0.13      0.05      3342
   macro avg       0.03      0.13      0.05      3342
weighted avg       0.03      0.13      0.05      3342

{'eval_loss': 0.8593205809593201, 'eval_precision': 0.0319693094629156, 'eval_recall': 0.13464991023339318, 'eval_f1': 0.05167068549776094, 'eval_accuracy': 0.7275281567101649, 'eval_runtime': 23.544, 'eval_samples_per_second': 71.483, 'eval_steps_per_second': 4.502, 'epoch': 1.13}
{'loss': 0.5606, 'learning_rate': 1.6598639455782314e-05, 'epoch': 1.7}
              precision    recall  f1-score   support

       NSWER       0.04      0.19      0.07      1659
     UESTION       0.12      0.31      0.17      1683

   micro avg       0.07      0.25      0.11      3342
   macro avg       0.08      0.25      0.12      3342
weighted avg       0.08      0.25      0.12      3342

{'eval_loss': 0.9168747067451477, 'eval_precision': 0.06995098446456759, 'eval_recall': 0.2519449431478157, 'eval_f1': 0.10949996748813318, 'eval_accuracy': 0.679548752540778, 'eval_runtime': 22.756, 'eval_samples_per_second': 73.958, 'eval_steps_per_second': 4.658, 'epoch': 1.7}
{'loss': 0.5337, 'learning_rate': 1.546485260770975e-05, 'epoch': 2.27}
              precision    recall  f1-score   support

       NSWER       0.05      0.19      0.07      1659
     UESTION       0.11      0.33      0.17      1683

   micro avg       0.07      0.26      0.11      3342
   macro avg       0.08      0.26      0.12      3342
weighted avg       0.08      0.26      0.12      3342

{'eval_loss': 0.8105162382125854, 'eval_precision': 0.0739787161002403, 'eval_recall': 0.2579293836026332, 'eval_f1': 0.11497932506335867, 'eval_accuracy': 0.7414816204943316, 'eval_runtime': 23.1306, 'eval_samples_per_second': 72.761, 'eval_steps_per_second': 4.583, 'epoch': 2.27}
{'loss': 0.4917, 'learning_rate': 1.433106575963719e-05, 'epoch': 2.83}
              precision    recall  f1-score   support

       NSWER       0.04      0.19      0.07      1659
     UESTION       0.07      0.28      0.11      1683

   micro avg       0.05      0.24      0.09      3342
   macro avg       0.06      0.24      0.09      3342
weighted avg       0.06      0.24      0.09      3342

{'eval_loss': 0.8621248006820679, 'eval_precision': 0.05498614958448753, 'eval_recall': 0.23758228605625373, 'eval_f1': 0.08930379034979193, 'eval_accuracy': 0.7316885567852319, 'eval_runtime': 23.1543, 'eval_samples_per_second': 72.686, 'eval_steps_per_second': 4.578, 'epoch': 2.83}
{'loss': 0.393, 'learning_rate': 1.3197278911564626e-05, 'epoch': 3.4}
              precision    recall  f1-score   support

       NSWER       0.10      0.27      0.15      1659
     UESTION       0.13      0.35      0.19      1683

   micro avg       0.12      0.31      0.17      3342
   macro avg       0.12      0.31      0.17      3342
weighted avg       0.12      0.31      0.17      3342

{'eval_loss': 0.6557269096374512, 'eval_precision': 0.11669496321448783, 'eval_recall': 0.3084979054458408, 'eval_f1': 0.1693356327502669, 'eval_accuracy': 0.8047387326903304, 'eval_runtime': 23.3625, 'eval_samples_per_second': 72.039, 'eval_steps_per_second': 4.537, 'epoch': 3.4}
{'loss': 0.3951, 'learning_rate': 1.2063492063492064e-05, 'epoch': 3.97}
              precision    recall  f1-score   support

       NSWER       0.10      0.28      0.15      1659
     UESTION       0.12      0.33      0.17      1683

   micro avg       0.11      0.30      0.16      3342
   macro avg       0.11      0.30      0.16      3342
weighted avg       0.11      0.30      0.16      3342

{'eval_loss': 0.787484347820282, 'eval_precision': 0.10813130229564472, 'eval_recall': 0.3016157989228007, 'eval_f1': 0.15919140871762474, 'eval_accuracy': 0.778565745686955, 'eval_runtime': 23.3395, 'eval_samples_per_second': 72.109, 'eval_steps_per_second': 4.542, 'epoch': 3.97}
{'loss': 0.2951, 'learning_rate': 1.0929705215419501e-05, 'epoch': 4.54}
              precision    recall  f1-score   support

       NSWER       0.10      0.27      0.15      1659
     UESTION       0.11      0.32      0.17      1683

   micro avg       0.11      0.30      0.16      3342
   macro avg       0.11      0.30      0.16      3342
weighted avg       0.11      0.30      0.16      3342

{'eval_loss': 0.8466928601264954, 'eval_precision': 0.10669815371404036, 'eval_recall': 0.2974266906044285, 'eval_f1': 0.15705482698688575, 'eval_accuracy': 0.7706097074239617, 'eval_runtime': 24.4427, 'eval_samples_per_second': 68.855, 'eval_steps_per_second': 4.337, 'epoch': 4.54}
{'loss': 0.2955, 'learning_rate': 9.795918367346939e-06, 'epoch': 5.1}
              precision    recall  f1-score   support

       NSWER       0.13      0.32      0.18      1659
     UESTION       0.15      0.36      0.21      1683

   micro avg       0.14      0.34      0.20      3342
   macro avg       0.14      0.34      0.20      3342
weighted avg       0.14      0.34      0.20      3342

{'eval_loss': 0.783517062664032, 'eval_precision': 0.13925925925925925, 'eval_recall': 0.3375224416517056, 'eval_f1': 0.19716832721552174, 'eval_accuracy': 0.7904548686460726, 'eval_runtime': 23.6904, 'eval_samples_per_second': 71.041, 'eval_steps_per_second': 4.474, 'epoch': 5.1}
{'loss': 0.2104, 'learning_rate': 8.662131519274378e-06, 'epoch': 5.67}
              precision    recall  f1-score   support

       NSWER       0.12      0.30      0.17      1659
     UESTION       0.15      0.37      0.21      1683

   micro avg       0.13      0.34      0.19      3342
   macro avg       0.13      0.34      0.19      3342
weighted avg       0.13      0.34      0.19      3342

{'eval_loss': 0.8774665594100952, 'eval_precision': 0.13212860830790893, 'eval_recall': 0.3369239976062238, 'eval_f1': 0.18981793661496962, 'eval_accuracy': 0.7844600863269799, 'eval_runtime': 23.9881, 'eval_samples_per_second': 70.16, 'eval_steps_per_second': 4.419, 'epoch': 5.67}
{'loss': 0.2362, 'learning_rate': 7.528344671201815e-06, 'epoch': 6.24}
              precision    recall  f1-score   support

       NSWER       0.14      0.31      0.19      1659
     UESTION       0.15      0.36      0.21      1683

   micro avg       0.14      0.34      0.20      3342
   macro avg       0.14      0.34      0.20      3342
weighted avg       0.14      0.34      0.20      3342

{'eval_loss': 0.8195622563362122, 'eval_precision': 0.14411990776325903, 'eval_recall': 0.33662477558348297, 'eval_f1': 0.20182992465016145, 'eval_accuracy': 0.794054909880025, 'eval_runtime': 24.4537, 'eval_samples_per_second': 68.824, 'eval_steps_per_second': 4.335, 'epoch': 6.24}
{'train_runtime': 772.3254, 'train_samples_per_second': 45.628, 'train_steps_per_second': 5.71, 'train_loss': 0.44682819574529475, 'epoch': 6.24}
              precision    recall  f1-score   support

       NSWER       0.11      0.29      0.16      5623
     UESTION       0.14      0.37      0.20      5693

   micro avg       0.12      0.33      0.18     11316
   macro avg       0.12      0.33      0.18     11316
weighted avg       0.12      0.33      0.18     11316

{'epoch': 6.24,
 'eval_accuracy': 0.8207392858570413,
 'eval_f1': 0.18017843289371605,
 'eval_loss': 0.5980286598205566,
 'eval_precision': 0.12414806895630096,
 'eval_recall': 0.328384588193708,
 'eval_runtime': 81.734,
 'eval_samples_per_second': 69.653,
 'eval_steps_per_second': 4.356}
Accuracy: 0.8207392858570413
PARAMETERS	model	xlm-roberta-base	data_dir	../../data/qa_token_classification	train_batch_size	8	learning_rate	2e-5	num_train_epochs	10	END 4745173: Thu 12 Oct 2023 12:15:40 PM EEST
